{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dynet_config\n",
    "dynet_config.set(\n",
    "    mem=4096,\n",
    "    autobatch=True,      # utilize autobatching\n",
    "    random_seed=1978     # simply for reproducibility here\n",
    ")\n",
    "import dynet as dy\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `dyNet` example: `pos` tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import utils as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change this string to match the path on your computer\n",
    "path_to_root = \"/Users/mcapizzi/Github/dynet_tutorial/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training data\n",
      "parsed 72914 sentences\n",
      "loading dev data\n",
      "parsed 7859 sentences\n",
      "loading test data\n",
      "parsed 2493 sentences\n"
     ]
    }
   ],
   "source": [
    "train_tokens, train_labels, _, _, test_tokens, test_labels = u.import_pos(path_to_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data consists of a `<list>` of `<list>` of tokens, and the labels are a `<list>` of `<list>` `pos` tags where each individual `<list>` is a training instance to be fed through the `RNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['for', 'six', 'years', ',', 't.'], ['IN', 'CD', 'NNS', ',', 'NNP'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens[0][:5], train_labels[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to build a map from `pos tag` to an index so that we can use `int` labels in our `RNN`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('IN', 0), ('CD', 1), ('NNS', 2), (',', 3), ('NNP', 4), ('VBZ', 5), ('VBN', 6), ('JJ', 7), ('DT', 8), ('NN', 9), (':', 10), ('CC', 11), ('.', 12), ('RB', 13), ('MD', 14), ('PRP', 15), ('VB', 16), ('RBR', 17), ('VBG', 18), ('POS', 19), ('$', 20), ('PRP$', 21), ('JJR', 22), ('WDT', 23), ('VBD', 24), ('TO', 25), ('``', 26), ('VBP', 27), (\"''\", 28), ('RP', 29), ('WP', 30), ('EX', 31), ('NNPS', 32), ('JJS', 33), ('(', 34), (')', 35), ('RBS', 36), ('WRB', 37), ('FW', 38), ('UH', 39), ('WP$', 40), ('PDT', 41), ('LS', 42), ('#', 43), ('SYM', 44)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2i = u.labels_to_index_map(train_labels)\n",
    "l2i.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you're interested, you can see https://catalog.ldc.upenn.edu/docs/LDC99T42/tagguid1.pdf for examples of each `pos tag`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now update `train_labels`, and `test_labels` to be `<list>` of `<list>` of `int`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = [[l2i[l] for l in sent] for sent in train_labels]\n",
    "train_labels[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 12]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = [[l2i[l] for l in sent] for sent in test_labels]\n",
    "test_labels[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for use during prediction, we'll also want a reverse of that map so we can go from `int` to `pos tag`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, 'IN'), (1, 'CD'), (2, 'NNS'), (3, ','), (4, 'NNP'), (5, 'VBZ'), (6, 'VBN'), (7, 'JJ'), (8, 'DT'), (9, 'NN'), (10, ':'), (11, 'CC'), (12, '.'), (13, 'RB'), (14, 'MD'), (15, 'PRP'), (16, 'VB'), (17, 'RBR'), (18, 'VBG'), (19, 'POS'), (20, '$'), (21, 'PRP$'), (22, 'JJR'), (23, 'WDT'), (24, 'VBD'), (25, 'TO'), (26, '``'), (27, 'VBP'), (28, \"''\"), (29, 'RP'), (30, 'WP'), (31, 'EX'), (32, 'NNPS'), (33, 'JJS'), (34, '('), (35, ')'), (36, 'RBS'), (37, 'WRB'), (38, 'FW'), (39, 'UH'), (40, 'WP$'), (41, 'PDT'), (42, 'LS'), (43, '#'), (44, 'SYM')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2l = dict((v,k) for k,v in l2i.items())\n",
    "i2l.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build architecture\n",
    "\n",
    "** all images from Chris Olah's fantastic [blog post on LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use an `RNN` to model the sequence of tokens in a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNN](images/RNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are plenty of variants out there of `RNN`s, the two most popular are `Long Short-Term Memory` (`GRU`) networks of `Gated Recurrent Unit` networks (`GRU`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_ | _\n",
    "-|-\n",
    "![LSTM](images/LSTM.png) | ![GRU](images/GRU.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize empty model\n",
    "\n",
    "See http://dynet.readthedocs.io/en/latest/python_ref.html#parametercollection\n",
    "\n",
    "The first thing to be done is initialize the `ParameterCollection()` which will house all the parameters that will be updated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_dynet.ParameterCollection at 0x109e49c00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_model = dy.ParameterCollection()    # used to be called dy.Model()\n",
    "RNN_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dimensions and layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have a few decisions to make on the size of your `RNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################\n",
    "# HYPERPARAMETER\n",
    "################\n",
    "# size of word embedding (if using \"random\", otherwise, dependent on the loaded embeddings)\n",
    "embedding_size = 300\n",
    "\n",
    "################\n",
    "# HYPERPARAMETER\n",
    "################\n",
    "# size of hidden layer of `RNN`\n",
    "hidden_size = 200\n",
    "\n",
    "################\n",
    "# HYPERPARAMETER\n",
    "################\n",
    "# number of layers in `RNN`\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two choices for how we want to embed the tokens in our sentences:\n",
    " 1. ...randomly initialize the word embeddings.\n",
    " 2. ...load some pretrained word embeddings.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### randomly initialized embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `embedding matrix` will be of size `size_vocabulary x embedding_dim` where the $i^{th}$ row of the matrix is the embedding vector for the $i^{th}$ indexed word.\n",
    "\n",
    "So first we'll need to build the `word-2-index` lookup table of all the words in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i_random = u.build_w2i_lookup(train_tokens)\n",
    "w2i_random[\"the\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pretrained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embeddings we'll use are from this paper: https://levyomer.files.wordpress.com/2014/04/dependency-based-word-embeddings-acl-2014.pdf <br>\n",
    "And can be downloaded here: https://levyomer.wordpress.com/2014/04/25/dependency-based-word-embeddings/\n",
    "\n",
    "In *most* cases, these vectors are ordered by frequency, so we can safely take the `top n` words to save some computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# emb_matrix_pretrained, w2i_pretrained = u.load_pretrained_embeddings(\n",
    "#     path.join(path_to_root, \"pretrained_embeddings.txt\"), \n",
    "#     take=10000\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have (1) an `embedding matrix` of size `num_words x embedding_dim` and (2) a `word-2-index` lookup table.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"embedding matrix shape: {}\".format(emb_matrix_pretrained.shape))\n",
    "# print(\"index for '{}': {}\".format(\"the\", w2i_pretrained[\"the\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build the actual `dyNet` parameters for the embeddings.  These *will* be updated during training, which will lead to \"catered\" embeddings specialized for our `spam/ham` task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### CHOOSE HERE which approach you want to use. ######\n",
    "# embedding_approach, embedding_dim = \"pretrained\", emb_matrix_pretrained.shape[1]\n",
    "embedding_approach, embedding_dim = \"random\", embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 37890)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if embedding_approach == \"pretrained\":\n",
    "    embedding_parameters = RNN_model.lookup_parameters_from_numpy(emb_matrix_pretrained)\n",
    "    w2i = w2i_pretrained    # ensure we use the correct lookup table\n",
    "elif embedding_approach == \"random\":\n",
    "    embedding_parameters = RNN_model.add_lookup_parameters((len(w2i_random)+1, embedding_dim))\n",
    "    w2i = w2i_random        # ensure we use the correct lookup table\n",
    "else:\n",
    "    raise Exception(\"you chose poorly...\")\n",
    "dy.parameter(embedding_parameters).npvalue().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add `RNN` unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dyNet` offers a few variants of the `RNN`, each of which is packaged in a simple \"bundle\" for you that can be built in one line.\n",
    "\n",
    "They all take *four* arguments:\n",
    " - number of layers in RNN\n",
    " - size of input (embeddings)\n",
    " - size of hidden layer\n",
    " - a `ParameterCollection()` to add the unit to\n",
    " \n",
    "See http://dynet.readthedocs.io/en/latest/builders.html for all of your options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_dynet.GRUBuilder at 0x28f9e2eb8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### CHOOSE HERE which approach you want to use. ######\n",
    "# RNN_unit = dy.LSTMBuilder(num_layers, embedding_dim, hidden_size, RNN_model)\n",
    "RNN_unit = dy.GRUBuilder(num_layers, embedding_dim, hidden_size, RNN_model)\n",
    "RNN_unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add projection layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless we set the `hidden_dim` of your `RNN` to be exactly the same size as the number of `pos_tags` (which is probably too small), we'll need to project the output of our `RNN`'s `hidden layer` down so that it is equal to the number of `pos tags`.\n",
    "\n",
    "So we'll add a `parameter matrix` and a `bias`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 45)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# W (hidden x num_labels) \n",
    "pW = RNN_model.add_parameters(\n",
    "        (hidden_size, len(list(l2i.keys())))\n",
    ")\n",
    "dy.parameter(pW).npvalue().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b (1 x num_labels)\n",
    "pb = RNN_model.add_parameters(\n",
    "        (len(list(l2i.keys())))        \n",
    ")\n",
    "# note: we are just giving one dimension (ignoring the \"1\" dimension)\n",
    "# this makes manipulating the shapes in forward_pass() below easier \n",
    "dy.parameter(pb).npvalue().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting words to indexes\n",
    "\n",
    "In order to access the word embedding for a given word, we need to know its `index` from our `word2index` lookup table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def words2indexes(seq_of_words, w2i_lookup):\n",
    "    \"\"\"\n",
    "    This function converts our sentence into a sequence of indexes that correspond to the rows in our embedding matrix\n",
    "    :param seq_of_words: the document as a <list> of words\n",
    "    :param w2i_lookup: the lookup table of {word:index} that we built earlier\n",
    "    \"\"\"\n",
    "    seq_of_idxs = []\n",
    "    for w in seq_of_words:\n",
    "        w = w.lower()            # lowercase\n",
    "        i = w2i_lookup.get(w, 0) # we use the .get() method to allow for default return value if the word is not found\n",
    "                                 # we've reserved the 0th row of embedding matrix for out-of-vocabulary words\n",
    "        seq_of_idxs.append(i)\n",
    "    return seq_of_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[146, 30, 29006]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_idxs = words2indexes([\"I\", \"like\", \"armadillos\"], w2i)\n",
    "sample_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forward operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_pass(x):\n",
    "    \"\"\"\n",
    "    This function will wrap all the steps needed to feed one sentence through the RNN\n",
    "    :param x: a <list> of indices\n",
    "    \"\"\"\n",
    "    # convert sequence of ints to sequence of embeddings\n",
    "    input_seq = [embedding_parameters[i] for i in x]   # embedding_parameters can be used like <dict>\n",
    "    # convert Parameters to Expressions\n",
    "    W = dy.parameter(pW)\n",
    "    b = dy.parameter(pb)\n",
    "    # initialize the RNN unit\n",
    "    rnn_seq = RNN_unit.initial_state()\n",
    "    # run each timestep through the RNN\n",
    "    rnn_hidden_outs = rnn_seq.transduce(input_seq)\n",
    "    # project each timestep's hidden output to size of labels\n",
    "    rnn_outputs = [dy.transpose(W) * h + b for h in rnn_hidden_outs]\n",
    "    return rnn_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of `forward_pass` is a `<list>` of `vector`s (one for each timestep) of size `num_labels`, and the values of each vector represent the weight the network gives to each label.  The `max` value represents the predicted `pos tag` for that token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14690343, -0.17027847, -0.10914128, -0.30618301, -0.1283239 ,\n",
       "       -0.02966462, -0.08975635,  0.15801041,  0.01355127,  0.11134554,\n",
       "        0.01307148,  0.24266118,  0.09195352, -0.06577423, -0.05001297,\n",
       "        0.190285  ,  0.16310844, -0.07441358,  0.1705557 ,  0.24324197,\n",
       "        0.22315116,  0.07148514,  0.18567711, -0.20747925, -0.044515  ,\n",
       "        0.21493933,  0.24246149,  0.32282019,  0.05646953, -0.09182185,\n",
       "       -0.09205592, -0.11433235, -0.22574994, -0.00709864,  0.20758262,\n",
       "       -0.04263326,  0.03176683,  0.14376125, -0.05891509,  0.19858375,\n",
       "       -0.17108503, -0.24123117,  0.05611552, -0.08769525,  0.14830303])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = \"i own 7 armadillos .\".split()\n",
    "sample = forward_pass(words2indexes(sample_sentence, w2i))\n",
    "sample[0].npvalue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### making predictions\n",
    "\n",
    "In order to make predictions, we need to take the `argmax` value of the output for **each** token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(list_of_outputs):\n",
    "    \"\"\"\n",
    "    This function will convert the outputs from forward_pass() to a <list> of label indexes\n",
    "    \"\"\"\n",
    "    # take the softmax of each timestep\n",
    "    # note: this step isn't actually necessary as the argmax of the raw outputs will come out the same\n",
    "    # but the softmax is more \"interpretable\" if needed for debugging\n",
    "    pred_probs = [dy.softmax(o) for o in list_of_outputs]     \n",
    "    # convert each timestep's output to a numpy array\n",
    "    pred_probs_np = [o.npvalue() for o in pred_probs]\n",
    "    # take the argmax for each step\n",
    "    pred_probs_idx = [np.argmax(o) for o in pred_probs_np]\n",
    "    return pred_probs_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27, 19, 19, 15, 11]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_predict = predict(sample)\n",
    "sample_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then easily revert these easily to their `pos tags`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('i', 'VBP'), ('own', 'POS'), ('7', 'POS'), ('armadillos', 'PRP'), ('.', 'CC')]\n"
     ]
    }
   ],
   "source": [
    "sample_predict_labels = [i2l[p] for p in sample_predict]\n",
    "print(list(zip(sample_sentence, sample_predict_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initializing a `trainer`\n",
    "See http://dynet.readthedocs.io/en/latest/python_ref.html#optimizers\n",
    "\n",
    "This decision is a big one.  It relates to what \"optimizer\" will be used to update the parameters.  Here I've chosen a *very simple* `trainer`, however the default `learning_rate` is almost never a good one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################\n",
    "# HYPERPARAMETER\n",
    "################\n",
    "trainer = dy.SimpleSGDTrainer(\n",
    "    m=RNN_model,\n",
    "    learning_rate=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### autobatching\n",
    "See http://dynet.readthedocs.io/en/latest/minibatch.html#automatic-mini-batching <br>\n",
    "and the technical details here: https://arxiv.org/pdf/1705.07860.pdf\n",
    "\n",
    "This is one of the real advantages of `dyNet` that is incredibly valuable when training `RNN`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one `epoch`\n",
    "\n",
    "Let's walk through *one* epoch (where our model sees all of our data *one* time).\n",
    "\n",
    "The most important step is `dy.renew_cg()` which starts off a \"clean\" computational graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`autobatching` allows us to feed each datapoint in one at a time, and `dyNet` will figure out how to \"optimize\" the operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the training data is large (as is the case for us), we can also feed in smaller batches of data for `autobatch`ing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(285, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################\n",
    "# HYPERPARAMETER\n",
    "################\n",
    "batch_size = 256\n",
    "num_batches_training = int(np.ceil(len(train_tokens) / batch_size))\n",
    "num_batches_testing = int(np.ceil(len(test_tokens) / batch_size))\n",
    "num_batches_training, num_batches_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1\n",
      "[('i', 'VBP'), ('own', 'POS'), ('7', 'POS'), ('armadillos', 'PRP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# iterate through the first 3 batches of training data (~1500 sentences)\n",
    "\n",
    "# j = batch index\n",
    "# k = sentence index (inside batch j)\n",
    "# l = token index (inside sentence k)\n",
    "# Note: we are reserving `i` as an index over epochs\n",
    "\n",
    "for j in range(3):\n",
    "    # begin a clean computational graph\n",
    "    dy.renew_cg()\n",
    "    # build the batch\n",
    "    batch_tokens = train_tokens[j*batch_size:(j+1)*batch_size]\n",
    "    batch_labels = train_labels[j*batch_size:(j+1)*batch_size]\n",
    "    # iterate through the batch\n",
    "    for k in range(len(batch_tokens)):\n",
    "        # prepare input: words to indexes\n",
    "        seq_of_idxs = words2indexes(batch_tokens[k], w2i)\n",
    "        # make a forward pass\n",
    "        preds = forward_pass(seq_of_idxs)\n",
    "        # calculate loss for each token in each example\n",
    "        loss = [dy.pickneglogsoftmax(preds[l], batch_labels[k][l]) for l in range(len(preds))]\n",
    "        # sum the loss for each token\n",
    "        sent_loss = dy.esum(loss)\n",
    "        # backpropogate the loss for the sentence\n",
    "        sent_loss.backward()\n",
    "        trainer.update()\n",
    "    if j % 5 == 0:\n",
    "        print(\"batch {}\".format(j+1))\n",
    "        sample = forward_pass(words2indexes(sample_sentence, w2i))\n",
    "        predictions = [i2l[p] for p in predict(sample)]\n",
    "        print(list(zip(sample_sentence, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_score(pred, true_y):\n",
    "    return 1 if pred == true_y else 0\n",
    "\n",
    "def check_sentence_score(sentence_scores):\n",
    "    return 0 if 1 in sentence_scores else 1\n",
    "\n",
    "def get_accuracy(flat_list_of_scores):\n",
    "    return float(sum(flat_list_of_scores) / len(flat_list_of_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(nested_preds, nested_true):\n",
    "    flat_scores = []\n",
    "    sentence_scores = []\n",
    "    for i in range(len(nested_true)):\n",
    "        scores = []\n",
    "        pred = nested_preds[i]\n",
    "        true = nested_true[i]\n",
    "        for p,t in zip(pred,true):\n",
    "            score = check_score(p,t)\n",
    "            scores.append(score)\n",
    "        sentence_scores.append(check_sentence_score(scores))\n",
    "        flat_scores.extend(scores)\n",
    "    overall_accuracy = get_accuracy(flat_scores)\n",
    "    sentence_accuracy = get_accuracy(sentence_scores)\n",
    "    return overall_accuracy, sentence_accuracy\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same `autobatch`ing format for getting predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    # j = batch index\n",
    "    # k = sentence index (inside batch j)\n",
    "    # l = token index (inside sentence k)\n",
    "    all_predictions = []\n",
    "\n",
    "    for j in range(num_batches_testing):\n",
    "        # begin a clean computational graph\n",
    "        dy.renew_cg()\n",
    "        # build the batch\n",
    "        batch_tokens = test_tokens[j*batch_size:(j+1)*batch_size]\n",
    "        batch_labels = test_tokens[j*batch_size:(j+1)*batch_size]\n",
    "        # iterate through the batch\n",
    "        for k in range(len(batch_tokens)):\n",
    "            # prepare input: words to indexes\n",
    "            seq_of_idxs = words2indexes(batch_tokens[k], w2i)\n",
    "            # make a forward pass\n",
    "            preds = forward_pass(seq_of_idxs)\n",
    "            label_preds = predict(preds)\n",
    "            all_predictions.append(label_preds)\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_predictions = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy: 0.10721283166738618\n",
      "sentence accuracy (all tags in sentence correct): 0.1183313277176093\n"
     ]
    }
   ],
   "source": [
    "overall_accuracy, sentence_accuracy = evaluate(final_predictions, test_labels)\n",
    "print(\"overall accuracy: {}\".format(overall_accuracy))\n",
    "print(\"sentence accuracy (all tags in sentence correct): {}\".format(sentence_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple epochs\n",
    "\n",
    "Obviously we need to run the model through the data multiple times to see the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################\n",
    "# HYPERPARAMETER\n",
    "################\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    # i = epoch index\n",
    "    # j = batch index\n",
    "    # k = sentence index (inside batch j)\n",
    "    # l = token index (inside sentence k)\n",
    "\n",
    "    epoch_losses = []\n",
    "    overall_accuracies = []\n",
    "    sentence_accuracies = []\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        epoch_loss = []\n",
    "        for j in range(num_batches_training):\n",
    "            # begin a clean computational graph\n",
    "            dy.renew_cg()\n",
    "            # build the batch\n",
    "            batch_tokens = train_tokens[j*batch_size:(j+1)*batch_size]\n",
    "            batch_labels = train_labels[j*batch_size:(j+1)*batch_size]\n",
    "            # iterate through the batch\n",
    "            for k in range(len(batch_tokens)):\n",
    "                # prepare input: words to indexes\n",
    "                seq_of_idxs = words2indexes(batch_tokens[k], w2i)\n",
    "                # make a forward pass\n",
    "                preds = forward_pass(seq_of_idxs)\n",
    "                # calculate loss for each token in each example\n",
    "                loss = [dy.pickneglogsoftmax(preds[l], batch_labels[k][l]) for l in range(len(preds))]\n",
    "                # sum the loss for each token\n",
    "                sent_loss = dy.esum(loss)\n",
    "                # backpropogate the loss for the sentence\n",
    "                sent_loss.backward()\n",
    "                trainer.update()\n",
    "                epoch_loss.append(sent_loss.npvalue())\n",
    "            # check prediction of sample sentence\n",
    "            if j % 250 == 0:\n",
    "                print(\"epoch {}, batch {}\".format(i+1, j+1))\n",
    "                sample = forward_pass(words2indexes(sample_sentence, w2i))\n",
    "                predictions = [i2l[p] for p in predict(sample)]\n",
    "                print(list(zip(sample_sentence, predictions)))\n",
    "        # record epoch loss\n",
    "        epoch_losses.append(np.sum(epoch_loss))\n",
    "        # get accuracy on test set\n",
    "        print(\"testing after epoch {}\".format(i+1))\n",
    "        epoch_predictions = test()\n",
    "        epoch_overall_accuracy, epoch_sentence_accuracy = evaluate(epoch_predictions, test_labels)\n",
    "        overall_accuracies.append(epoch_overall_accuracy)\n",
    "        sentence_accuracies.append(epoch_sentence_accuracy)\n",
    "        \n",
    "    return epoch_losses, overall_accuracies, sentence_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, batch 1\n",
      "[('i', 'IN'), ('own', 'NN'), ('7', 'DT'), ('armadillos', 'DT'), ('.', 'NNS')]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-53a078130744>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverall_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-a9766d09e0fd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0msent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mesum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# backpropogate the loss for the sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0msent_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mepoch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnpvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses, overall_accs, sentence_accs = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(overall_accs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sentence accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(sentence_accs)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
