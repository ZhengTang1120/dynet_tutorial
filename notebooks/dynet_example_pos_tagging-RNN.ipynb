{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dynet_config\n",
    "dynet_config.set(\n",
    "    mem=4096,\n",
    "    autobatch=True,      # utilize autobatching\n",
    "    random_seed=1978     # simply for reproducibility here\n",
    ")\n",
    "import dynet as dy\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `dyNet` example: `pos` tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import utils as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change this string to match the path on your computer\n",
    "path_to_root = \"/Users/mcapizzi/Github/dynet_tutorial/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training data\n",
      "parsed 72914 sentences\n",
      "loading dev data\n",
      "parsed 7859 sentences\n",
      "loading test data\n",
      "parsed 2493 sentences\n"
     ]
    }
   ],
   "source": [
    "train_tokens, train_labels, _, _, test_tokens, test_labels = u.import_pos(path_to_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data consists of a `<list>` of `<list>` of tokens, and the labels are a `<list>` of `<list>` `pos` tags where each individual `<list>` is a training instance to be fed through the `RNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['for', 'six', 'years', ',', 't.'], ['IN', 'CD', 'NNS', ',', 'NNP'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens[0][:5], train_labels[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to build a map from `pos tag` to an index so that we can use `int` labels in our `RNN`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('IN', 0), ('CD', 1), ('NNS', 2), (',', 3), ('NNP', 4), ('VBZ', 5), ('VBN', 6), ('JJ', 7), ('DT', 8), ('NN', 9), (':', 10), ('CC', 11), ('.', 12), ('RB', 13), ('MD', 14), ('PRP', 15), ('VB', 16), ('RBR', 17), ('VBG', 18), ('POS', 19), ('$', 20), ('PRP$', 21), ('JJR', 22), ('WDT', 23), ('VBD', 24), ('TO', 25), ('``', 26), ('VBP', 27), (\"''\", 28), ('RP', 29), ('WP', 30), ('EX', 31), ('NNPS', 32), ('JJS', 33), ('(', 34), (')', 35), ('RBS', 36), ('WRB', 37), ('FW', 38), ('UH', 39), ('WP$', 40), ('PDT', 41), ('LS', 42), ('#', 43), ('SYM', 44)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2i = u.labels_to_index_map(train_labels)\n",
    "l2i.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you're interested, you can see https://catalog.ldc.upenn.edu/docs/LDC99T42/tagguid1.pdf for examples of each `pos tag`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now update `train_labels`, and `test_labels` to be `<list>` of `<list>` of `int`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = [[l2i[l] for l in sent] for sent in train_labels]\n",
    "train_labels[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 12]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = [[l2i[l] for l in sent] for sent in test_labels]\n",
    "test_labels[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for use during prediction, we'll also want a reverse of that map so we can go from `int` to `pos tag`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, 'IN'), (1, 'CD'), (2, 'NNS'), (3, ','), (4, 'NNP'), (5, 'VBZ'), (6, 'VBN'), (7, 'JJ'), (8, 'DT'), (9, 'NN'), (10, ':'), (11, 'CC'), (12, '.'), (13, 'RB'), (14, 'MD'), (15, 'PRP'), (16, 'VB'), (17, 'RBR'), (18, 'VBG'), (19, 'POS'), (20, '$'), (21, 'PRP$'), (22, 'JJR'), (23, 'WDT'), (24, 'VBD'), (25, 'TO'), (26, '``'), (27, 'VBP'), (28, \"''\"), (29, 'RP'), (30, 'WP'), (31, 'EX'), (32, 'NNPS'), (33, 'JJS'), (34, '('), (35, ')'), (36, 'RBS'), (37, 'WRB'), (38, 'FW'), (39, 'UH'), (40, 'WP$'), (41, 'PDT'), (42, 'LS'), (43, '#'), (44, 'SYM')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2l = dict((v,k) for k,v in l2i.items())\n",
    "i2l.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build architecture\n",
    "\n",
    "** all images from Chris Olah's fantastic [blog post on LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use an `RNN` to model the sequence of tokens in a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNN](images/RNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are plenty of variants out there of `RNN`s, the two most popular are `Long Short-Term Memory` (`GRU`) networks of `Gated Recurrent Unit` networks (`GRU`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_ | _\n",
    "-|-\n",
    "![LSTM](images/LSTM.png) | ![GRU](images/GRU.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize empty model\n",
    "\n",
    "See http://dynet.readthedocs.io/en/latest/python_ref.html#parametercollection\n",
    "\n",
    "The first thing to be done is initialize the `ParameterCollection()` which will house all the parameters that will be updated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_dynet.ParameterCollection at 0x1089e3c00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_model = dy.ParameterCollection()    # used to be called dy.Model()\n",
    "RNN_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dimensions and layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have a few decisions to make on the size of your `RNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################\n",
    "# HYPERPARAMETER\n",
    "################\n",
    "# size of word embedding (if using \"random\", otherwise, dependent on the loaded embeddings)\n",
    "embedding_size = 300\n",
    "\n",
    "################\n",
    "# HYPERPARAMETER\n",
    "################\n",
    "# size of hidden layer of `RNN`\n",
    "hidden_size = 200\n",
    "\n",
    "################\n",
    "# HYPERPARAMETER\n",
    "################\n",
    "# number of layers in `RNN`\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two choices for how we want to embed the tokens in our sentences:\n",
    " 1. ...randomly initialize the word embeddings.\n",
    " 2. ...load some pretrained word embeddings.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### randomly initialized embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `embedding matrix` will be of size `size_vocabulary x embedding_dim` where the $i^{th}$ row of the matrix is the embedding vector for the $i^{th}$ indexed word.\n",
    "\n",
    "So first we'll need to build the `word-2-index` lookup table of all the words in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i_random = u.build_w2i_lookup(train_tokens)\n",
    "w2i_random[\"the\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pretrained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embeddings we'll use are from this paper: https://levyomer.files.wordpress.com/2014/04/dependency-based-word-embeddings-acl-2014.pdf <br>\n",
    "And can be downloaded here: https://levyomer.wordpress.com/2014/04/25/dependency-based-word-embeddings/\n",
    "\n",
    "In *most* cases, these vectors are ordered by frequency, so we can safely take the `top n` words to save some computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# emb_matrix_pretrained, w2i_pretrained = u.load_pretrained_embeddings(\n",
    "#     path.join(path_to_root, \"pretrained_embeddings.txt\"), \n",
    "#     take=10000\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have (1) an `embedding matrix` of size `num_words x embedding_dim` and (2) a `word-2-index` lookup table.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"embedding matrix shape: {}\".format(emb_matrix_pretrained.shape))\n",
    "# print(\"index for '{}': {}\".format(\"the\", w2i_pretrained[\"the\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build the actual `dyNet` parameters for the embeddings.  These *will* be updated during training, which will lead to \"catered\" embeddings specialized for our `spam/ham` task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### CHOOSE HERE which approach you want to use. ######\n",
    "# embedding_approach, embedding_dim = \"pretrained\", emb_matrix_pretrained.shape[1]\n",
    "embedding_approach, embedding_dim = \"random\", embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 37890)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if embedding_approach == \"pretrained\":\n",
    "    embedding_parameters = RNN_model.lookup_parameters_from_numpy(emb_matrix_pretrained)\n",
    "    w2i = w2i_pretrained    # ensure we use the correct lookup table\n",
    "elif embedding_approach == \"random\":\n",
    "    embedding_parameters = RNN_model.add_lookup_parameters((len(w2i_random)+1, embedding_dim))\n",
    "    w2i = w2i_random        # ensure we use the correct lookup table\n",
    "else:\n",
    "    raise Exception(\"you chose poorly...\")\n",
    "dy.parameter(embedding_parameters).npvalue().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add `RNN` unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dyNet` offers a few variants of the `RNN`, each of which is packaged in a simple \"bundle\" for you that can be built in one line.\n",
    "\n",
    "They all take *four* arguments:\n",
    " - number of layers in RNN\n",
    " - size of input (embeddings)\n",
    " - size of hidden layer\n",
    " - a `ParameterCollection()` to add the unit to\n",
    " \n",
    "See http://dynet.readthedocs.io/en/latest/builders.html for all of your options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_dynet.GRUBuilder at 0x209073eb8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### CHOOSE HERE which approach you want to use. ######\n",
    "# RNN_unit = dy.LSTMBuilder(num_layers, embedding_dim, hidden_size, RNN_model)\n",
    "RNN_unit = dy.GRUBuilder(num_layers, embedding_dim, hidden_size, RNN_model)\n",
    "RNN_unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add projection layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless we set the `hidden_dim` of your `RNN` to be exactly the same size as the number of `pos_tags` (which is probably too small), we'll need to project the output of our `RNN`'s `hidden layer` down so that it is equal to the number of `pos tags`.\n",
    "\n",
    "So we'll add a `parameter matrix` and a `bias`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 45)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# W (hidden x num_labels) \n",
    "pW = RNN_model.add_parameters(\n",
    "        (hidden_size, len(list(l2i.keys())))\n",
    ")\n",
    "dy.parameter(pW).npvalue().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b (1 x num_labels)\n",
    "pb = RNN_model.add_parameters(\n",
    "        (len(list(l2i.keys())))        \n",
    ")\n",
    "# note: we are just giving one dimension (ignoring the \"1\" dimension)\n",
    "# this makes manipulating the shapes in forward_pass() below easier \n",
    "dy.parameter(pb).npvalue().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting words to indexes\n",
    "\n",
    "In order to access the word embedding for a given word, we need to know its `index` from our `word2index` lookup table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def words2indexes(seq_of_words, w2i_lookup):\n",
    "    \"\"\"\n",
    "    This function converts our sentence into a sequence of indexes that correspond to the rows in our embedding matrix\n",
    "    :param seq_of_words: the document as a <list> of words\n",
    "    :param w2i_lookup: the lookup table of {word:index} that we built earlier\n",
    "    \"\"\"\n",
    "    seq_of_idxs = []\n",
    "    for w in seq_of_words:\n",
    "        w = w.lower()            # lowercase\n",
    "        i = w2i_lookup.get(w, 0) # we use the .get() method to allow for default return value if the word is not found\n",
    "                                 # we've reserved the 0th row of embedding matrix for out-of-vocabulary words\n",
    "        seq_of_idxs.append(i)\n",
    "    return seq_of_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[146, 30, 29006]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_idxs = words2indexes([\"I\", \"like\", \"armadillos\"], w2i)\n",
    "sample_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forward operation\n",
    "\n",
    "See http://dynet.readthedocs.io/en/latest/tutorials_notebooks/RNNs.html for an in-depth explanation of how to use the `RNN` cells in `dynet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_pass(x):\n",
    "    \"\"\"\n",
    "    This function will wrap all the steps needed to feed one sentence through the RNN\n",
    "    :param x: a <list> of indices\n",
    "    \"\"\"\n",
    "    # convert sequence of ints to sequence of embeddings\n",
    "    input_seq = [embedding_parameters[i] for i in x]   # embedding_parameters can be used like <dict>\n",
    "    # convert Parameters to Expressions\n",
    "    W = dy.parameter(pW)\n",
    "    b = dy.parameter(pb)\n",
    "    # initialize the RNN unit\n",
    "    rnn_seq = RNN_unit.initial_state()\n",
    "    # run each timestep through the RNN\n",
    "    rnn_hidden_outs = rnn_seq.transduce(input_seq)\n",
    "    # project each timestep's hidden output to size of labels\n",
    "    rnn_outputs = [dy.transpose(W) * h + b for h in rnn_hidden_outs]\n",
    "    return rnn_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of `forward_pass` is a `<list>` of `vector`s (one for each timestep) of size `num_labels`, and the values of each vector represent the weight the network gives to each label.  The `max` value represents the predicted `pos tag` for that token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14690343, -0.17027847, -0.10914128, -0.30618301, -0.1283239 ,\n",
       "       -0.02966462, -0.08975635,  0.15801041,  0.01355127,  0.11134554,\n",
       "        0.01307148,  0.24266118,  0.09195352, -0.06577423, -0.05001297,\n",
       "        0.190285  ,  0.16310844, -0.07441358,  0.1705557 ,  0.24324197,\n",
       "        0.22315116,  0.07148514,  0.18567711, -0.20747925, -0.044515  ,\n",
       "        0.21493933,  0.24246149,  0.32282019,  0.05646953, -0.09182185,\n",
       "       -0.09205592, -0.11433235, -0.22574994, -0.00709864,  0.20758262,\n",
       "       -0.04263326,  0.03176683,  0.14376125, -0.05891509,  0.19858375,\n",
       "       -0.17108503, -0.24123117,  0.05611552, -0.08769525,  0.14830303])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = \"i own 7 armadillos .\".split()\n",
    "sample = forward_pass(words2indexes(sample_sentence, w2i))\n",
    "sample[0].npvalue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### making predictions\n",
    "\n",
    "In order to make predictions, we need to take the `argmax` value of the output for **each** token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(list_of_outputs):\n",
    "    \"\"\"\n",
    "    This function will convert the outputs from forward_pass() to a <list> of label indexes\n",
    "    \"\"\"\n",
    "    # take the softmax of each timestep\n",
    "    # note: this step isn't actually necessary as the argmax of the raw outputs will come out the same\n",
    "    # but the softmax is more \"interpretable\" if needed for debugging\n",
    "    pred_probs = [dy.softmax(o) for o in list_of_outputs]     \n",
    "    # convert each timestep's output to a numpy array\n",
    "    pred_probs_np = [o.npvalue() for o in pred_probs]\n",
    "    # take the argmax for each step\n",
    "    pred_probs_idx = [np.argmax(o) for o in pred_probs_np]\n",
    "    return pred_probs_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27, 19, 19, 15, 11]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_predict = predict(sample)\n",
    "sample_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then easily revert these easily to their `pos tags`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('i', 'VBP'), ('own', 'POS'), ('7', 'POS'), ('armadillos', 'PRP'), ('.', 'CC')]\n"
     ]
    }
   ],
   "source": [
    "sample_predict_labels = [i2l[p] for p in sample_predict]\n",
    "print(list(zip(sample_sentence, sample_predict_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initializing a `trainer`\n",
    "See http://dynet.readthedocs.io/en/latest/python_ref.html#optimizers\n",
    "\n",
    "This decision is a big one.  It relates to what \"optimizer\" will be used to update the parameters.  Here I've chosen a *very simple* `trainer`, however the default `learning_rate` is almost never a good one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################\n",
    "# HYPERPARAMETER\n",
    "################\n",
    "trainer = dy.SimpleSGDTrainer(\n",
    "    m=RNN_model,\n",
    "    learning_rate=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### autobatching\n",
    "See http://dynet.readthedocs.io/en/latest/minibatch.html#automatic-mini-batching <br>\n",
    "and the technical details here: https://arxiv.org/pdf/1705.07860.pdf\n",
    "\n",
    "This is one of the real advantages of `dyNet` that is incredibly valuable when training `RNN`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one `epoch`\n",
    "\n",
    "Let's walk through *one* epoch (where our model sees all of our data *one* time).\n",
    "\n",
    "The most important step is `dy.renew_cg()` which starts off a \"clean\" computational graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`autobatching` allows us to feed each datapoint in one at a time, and `dyNet` will figure out how to \"optimize\" the operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the training data is large (as is the case for us), we can also feed in smaller batches of data for `autobatch`ing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(285, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################\n",
    "# HYPERPARAMETER\n",
    "################\n",
    "batch_size = 256\n",
    "num_batches_training = int(np.ceil(len(train_tokens) / batch_size))\n",
    "num_batches_testing = int(np.ceil(len(test_tokens) / batch_size))\n",
    "num_batches_training, num_batches_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1\n",
      "[('i', 'VBP'), ('own', 'POS'), ('7', 'POS'), ('armadillos', 'PRP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# iterate through the first 3 batches of training data (~1500 sentences)\n",
    "\n",
    "# j = batch index\n",
    "# k = sentence index (inside batch j)\n",
    "# l = token index (inside sentence k)\n",
    "# Note: we are reserving `i` as an index over epochs\n",
    "\n",
    "for j in range(3):\n",
    "    # begin a clean computational graph\n",
    "    dy.renew_cg()\n",
    "    # build the batch\n",
    "    batch_tokens = train_tokens[j*batch_size:(j+1)*batch_size]\n",
    "    batch_labels = train_labels[j*batch_size:(j+1)*batch_size]\n",
    "    # iterate through the batch\n",
    "    for k in range(len(batch_tokens)):\n",
    "        # prepare input: words to indexes\n",
    "        seq_of_idxs = words2indexes(batch_tokens[k], w2i)\n",
    "        # make a forward pass\n",
    "        preds = forward_pass(seq_of_idxs)\n",
    "        # calculate loss for each token in each example\n",
    "        loss = [dy.pickneglogsoftmax(preds[l], batch_labels[k][l]) for l in range(len(preds))]\n",
    "        # sum the loss for each token\n",
    "        sent_loss = dy.esum(loss)\n",
    "        # backpropogate the loss for the sentence\n",
    "        sent_loss.backward()\n",
    "        trainer.update()\n",
    "    if j % 5 == 0:\n",
    "        print(\"batch {}\".format(j+1))\n",
    "        sample = forward_pass(words2indexes(sample_sentence, w2i))\n",
    "        predictions = [i2l[p] for p in predict(sample)]\n",
    "        print(list(zip(sample_sentence, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_score(pred, true_y):\n",
    "    return 1 if pred == true_y else 0\n",
    "\n",
    "def check_sentence_score(sentence_scores):\n",
    "    return 0 if 0 in sentence_scores else 1\n",
    "\n",
    "def get_accuracy(flat_list_of_scores):\n",
    "    return float(sum(flat_list_of_scores) / len(flat_list_of_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(nested_preds, nested_true):\n",
    "    flat_scores = []\n",
    "    sentence_scores = []\n",
    "    for i in range(len(nested_true)):\n",
    "        scores = []\n",
    "        pred = nested_preds[i]\n",
    "        true = nested_true[i]\n",
    "        for p,t in zip(pred,true):\n",
    "            score = check_score(p,t)\n",
    "            scores.append(score)\n",
    "        sentence_scores.append(check_sentence_score(scores))\n",
    "        flat_scores.extend(scores)\n",
    "    overall_accuracy = get_accuracy(flat_scores)\n",
    "    sentence_accuracy = get_accuracy(sentence_scores)\n",
    "    return overall_accuracy, sentence_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same `autobatch`ing format for getting predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    # j = batch index\n",
    "    # k = sentence index (inside batch j)\n",
    "    # l = token index (inside sentence k)\n",
    "    all_predictions = []\n",
    "\n",
    "    for j in range(num_batches_testing):\n",
    "        # begin a clean computational graph\n",
    "        dy.renew_cg()\n",
    "        # build the batch\n",
    "        batch_tokens = test_tokens[j*batch_size:(j+1)*batch_size]\n",
    "        batch_labels = test_tokens[j*batch_size:(j+1)*batch_size]\n",
    "        # iterate through the batch\n",
    "        for k in range(len(batch_tokens)):\n",
    "            # prepare input: words to indexes\n",
    "            seq_of_idxs = words2indexes(batch_tokens[k], w2i)\n",
    "            # make a forward pass\n",
    "            preds = forward_pass(seq_of_idxs)\n",
    "            label_preds = predict(preds)\n",
    "            all_predictions.append(label_preds)\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_predictions = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy: 0.10721283166738618\n",
      "sentence accuracy (all tags in sentence correct): 0.0\n"
     ]
    }
   ],
   "source": [
    "overall_accuracy, sentence_accuracy = evaluate(final_predictions, test_labels)\n",
    "print(\"overall accuracy: {}\".format(overall_accuracy))\n",
    "print(\"sentence accuracy (all tags in sentence correct): {}\".format(sentence_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple epochs\n",
    "\n",
    "Obviously we need to run the model through the data multiple times to see the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################\n",
    "# HYPERPARAMETER\n",
    "################\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    # i = epoch index\n",
    "    # j = batch index\n",
    "    # k = sentence index (inside batch j)\n",
    "    # l = token index (inside sentence k)\n",
    "\n",
    "    epoch_losses = []\n",
    "    overall_accuracies = []\n",
    "    sentence_accuracies = []\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        epoch_loss = []\n",
    "        for j in range(num_batches_training):\n",
    "            # begin a clean computational graph\n",
    "            dy.renew_cg()\n",
    "            # build the batch\n",
    "            batch_tokens = train_tokens[j*batch_size:(j+1)*batch_size]\n",
    "            batch_labels = train_labels[j*batch_size:(j+1)*batch_size]\n",
    "            # iterate through the batch\n",
    "            for k in range(len(batch_tokens)):\n",
    "                # prepare input: words to indexes\n",
    "                seq_of_idxs = words2indexes(batch_tokens[k], w2i)\n",
    "                # make a forward pass\n",
    "                preds = forward_pass(seq_of_idxs)\n",
    "                # calculate loss for each token in each example\n",
    "                loss = [dy.pickneglogsoftmax(preds[l], batch_labels[k][l]) for l in range(len(preds))]\n",
    "                # sum the loss for each token\n",
    "                sent_loss = dy.esum(loss)\n",
    "                # backpropogate the loss for the sentence\n",
    "                sent_loss.backward()\n",
    "                trainer.update()\n",
    "                epoch_loss.append(sent_loss.npvalue())\n",
    "            # check prediction of sample sentence\n",
    "            if j % 250 == 0:\n",
    "                print(\"epoch {}, batch {}\".format(i+1, j+1))\n",
    "                sample = forward_pass(words2indexes(sample_sentence, w2i))\n",
    "                predictions = [i2l[p] for p in predict(sample)]\n",
    "                print(list(zip(sample_sentence, predictions)))\n",
    "        # record epoch loss\n",
    "        epoch_losses.append(np.sum(epoch_loss))\n",
    "        # get accuracy on test set\n",
    "        print(\"testing after epoch {}\".format(i+1))\n",
    "        epoch_predictions = test()\n",
    "        epoch_overall_accuracy, epoch_sentence_accuracy = evaluate(epoch_predictions, test_labels)\n",
    "        overall_accuracies.append(epoch_overall_accuracy)\n",
    "        sentence_accuracies.append(epoch_sentence_accuracy)\n",
    "        \n",
    "    return epoch_losses, overall_accuracies, sentence_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, batch 1\n",
      "[('i', 'IN'), ('own', 'NN'), ('7', 'DT'), ('armadillos', 'DT'), ('.', 'NNS')]\n",
      "epoch 1, batch 251\n",
      "[('i', 'PRP'), ('own', 'VBP'), ('7', 'CD'), ('armadillos', 'NNS'), ('.', '.')]\n",
      "testing after epoch 1\n",
      "epoch 2, batch 1\n",
      "[('i', 'PRP'), ('own', 'VBP'), ('7', 'CD'), ('armadillos', 'NNS'), ('.', '.')]\n",
      "epoch 2, batch 251\n",
      "[('i', 'PRP'), ('own', 'VBP'), ('7', 'CD'), ('armadillos', 'NNS'), ('.', '.')]\n",
      "testing after epoch 2\n",
      "epoch 3, batch 1\n",
      "[('i', 'PRP'), ('own', 'VBP'), ('7', 'CD'), ('armadillos', 'NNS'), ('.', '.')]\n",
      "epoch 3, batch 251\n",
      "[('i', 'PRP'), ('own', 'VBP'), ('7', 'CD'), ('armadillos', 'NNS'), ('.', '.')]\n",
      "testing after epoch 3\n",
      "epoch 4, batch 1\n",
      "[('i', 'PRP'), ('own', 'VBP'), ('7', 'CD'), ('armadillos', 'NNS'), ('.', '.')]\n",
      "epoch 4, batch 251\n",
      "[('i', 'PRP'), ('own', 'VBP'), ('7', 'CD'), ('armadillos', 'NNS'), ('.', '.')]\n",
      "testing after epoch 4\n",
      "epoch 5, batch 1\n",
      "[('i', 'PRP'), ('own', 'VBP'), ('7', 'CD'), ('armadillos', 'NNS'), ('.', '.')]\n",
      "epoch 5, batch 251\n",
      "[('i', 'PRP'), ('own', 'VBP'), ('7', 'CD'), ('armadillos', 'NNS'), ('.', '.')]\n",
      "testing after epoch 5\n"
     ]
    }
   ],
   "source": [
    "losses, overall_accs, sentence_accs = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAD8CAYAAACyyUlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21809eb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xt4VfWd7/H3h0C4X4REQMIlQdoKalEzeBfsFXuRitNW\n26rYWq3WM+dMH2eOHud0znBOHzvPODOdtoJaS+ulrbV2tFR0nGklYuuNoAIigklAuRNA7tck3/PH\nXombGMwGkqxcPq/nyePav/Vba3/Xkr0+WZfsnyICMzOzbmkXYGZm7YMDwczMAAeCmZklHAhmZgY4\nEMzMLOFAMDMzwIFgZmYJB4KZmQEOBDMzS3RPu4CjUVBQEGPGjEm7DDOzDmXRokVbIqKwuX4dKhDG\njBlDeXl52mWYmXUokt7OpZ8vGZmZGeBAMDOzhAPBzMwAB4KZmSUcCGZmBjgQzMws4UAwMzOgg/0d\ngpl1TBHBlt0HqareTdWWPWzYsR8iQAJANEwihJRpI2lX/cz618nc9/XLas/8t6n1Z7XXL/8BdWS3\n16+fw95Xhy/XRB1N9mti/Q1zmlj/OWOH0K9n6x6yHQhm1mL2Haxl1ZY9VG3ZTVX1nsx0EgK79tek\nXV6H9ofvTObkE/u16ns4EMzsqNTVBeu276MqOdhnDvqZ6fU79h/Wd8Sg3pQU9uWyM0ZQUtCXksJ+\nlBT25aSBvenW7b1fnyMi+S9E9uukLTMdDdPv9T18ufp1ZS9Hjv2C92Y29b6HLXcUddCwrshaZ9Pb\nVb+uxusHKDqhN63NgWBmTdqx9xCVDb/p704O+ntYtXUPB2vqGvr179WdksJ+nF0y5LCD/pghfemd\nn5fTe2VfwklaWnhrLBcOBLMu7GBNHe9s20Nl9uWdZHrrnoMN/bp3E6OG9KGkoC+TP1xISUFfipOD\nf0G//MOu8VvHlVMgSJoK/BuQB9wXEd9vNH80MAcoBLYBX4uItUn7Y2SeZuoB/Cgi7m607FygJCJO\nPd6NMbP3iwg27zpAZfX7r+uv2baXuqzLE4X9e1Jc0JdPTRhKSUG/5KDfl5GD+9Ajzw8ldnbNBoKk\nPOAu4JPAWmChpLkR8UZWtzuBByLifkkfA+4ArgI2AOdGxAFJ/YDXk2XXJ+ueDuxu2U0y65r2HKhh\n1ZY9VGZf19+ym1XVe9hzsLahX68e3Sgu6MepIwYy7aMnUVKYOfAXF/ZlQK8eKW6BpS2XM4RJQEVE\nVAFIehiYBmQHwnjgO8n0fOBxgIg4mNWnJ1l/95AExHeA64FHjrF+sy6lti5Y++7e5GB/+CWejTvf\nu6Er1d/Q7Ufp6MGMLexLcUHm2v6wAb0Ou6FrVi+XQBgBrMl6vRY4u1GfxcB0MpeVLgP6SxoSEVsl\njQTmAScDf1N/dgD8X+Cfgb3HUb9Zp7Rtz3vP7Nc/wbNqyx7e3rqXg7Xv3dAd2LsHJYV9Of/kAkoK\n+zbc1B09pA+9euR2Q9esXkvdVL4F+LGkGcACYB1QCxARa4DTJZ0EPC7pUWA4MDYi/lrSmA9asaTr\nyZxFMGrUqBYq1yx9+w/V8vbWvYcf+LdkDvzb9x5q6NcjT4wekjnYf/yUoclBP3PgP6FPD9/QtRaT\nSyCsA0ZmvS5K2hokv/VPh4ZLQZdHxPbGfSS9DlxI5uZzqaTVSQ0nSiqLiCmN3zwi7gXuBSgtLY3G\n883as7q6YOPO/Q2PblYml3pWbdnN2nf3Hfa8+dABPSkp6MdnTxtOcUFfxiaPb44Y1JvuvqFrbSCX\nQFgIjJNUTCYIrgC+kt1BUgGwLSLqgNvIPHGEpCJga0Tsk3QCcAHwrxHxKDA76TMGeKKpMDDrKHbt\nP3TYEzyVW/awKnm979B7N3T75OdRUtiXM0aewPQziigpzBz4xxT0bfWvJTBrTrP/AiOiRtLNwNNk\nHjudExHLJM0EyiNiLjAFuENSkLlk9O1k8VOAf07aBdwZEUtbYTvM2tzqLXuYt3QDTy7dwLL1Oxva\nuwlGDs48s39OyZDk8k5fSgr6MXRAT1/isXZLER3nKkxpaWmUl5enXYZ1Yau27OHJpRuYt2QDb2zI\nhMDEkYP4xCknMm5of0oK+jJqSB96dvcNXWs/JC2KiNLm+vkc1awZ9SHwxJINLE9C4IxRg/i7z57C\nJacNZ8Sg1v+OGbO24EAwa0JV9e7MmcDSjQ0hcKZDwDo5B4JZoj4EnliygTc37gLeC4HPnDackxwC\n1sk5EKxLq6zezZNLNjBv6XshcNboE/jfnxvPJacOcwhYl+JAsC7HIWDWNAeCdQkVmzOXg57MCoHS\n0Sfw3c+N55LThjF8oEPAzIFgnVZ9CMxbsoEVmxwCZs1xIFinUrF5F/OWbOTJpZkQkDIh8PefH88l\npw5n2MBeaZdo1m45EKzDqw+BeUvXs3LT7oYQ+D+fH88lpw1n6ACHgFkuHAjWIb21aVfD10bUh8Bf\njB7sEDA7Dg4E6zDqQ2Dekg28tTkJgTGD+YdLJzD11GEOAbPj5ECwdm3lpl3MW5I5E2gcApecOowT\nHQJmLcaBYO3Oyk27eCIJgYokBCaNGczMaROYOsEhYNZaHAiWuohg5abdDfcEskPgaoeAWZtxIFgq\nGkJgyXrmLd1AZfUeJDi7eDDXnDuBT586jBP7OwTM2pIDwdpMRLBi066Gr42orN5DN8Gk4sHMOG+M\nQ8AsZTkFgqSpwL+RGTHtvoj4fqP5o8kMm1kIbAO+FhFrk/bHgG5AD+BHEXG3pD7Ab4CxQC3w+4i4\ntYW2ydqR+hCYl4RAVRICZxcPYcb5xUydMIzC/j3TLtPMyCEQJOUBdwGfBNYCCyXNjYg3srrdCTwQ\nEfdL+hhwB3AVsAE4NyIOSOoHvC5pLrCdzHCa8yXlA3+UdElEPNWym2dpiAje3LgrGU/g8BD4+vnF\nfNohYNYu5XKGMAmoiIgqAEkPA9OA7EAYD3wnmZ4PPA4QEQez+vQkc6ZAROxN+hERByW9AhQd+2ZY\n2upDoP4R0aotmRA4p8QhYNZR5BIII4A1Wa/XAmc36rMYmE7mstJlQH9JQyJiq6SRwDzgZOBvImJ9\n9oKSBgGfT5a1DiQiWL5hV8O3iNaHwLljh/CNCzMhUNDPIWDWUbTUTeVbgB9LmgEsANaRuTdARKwB\nTpd0EvC4pEcjYhOApO7Ar4Af1p+BNCbpeuB6gFGjRrVQuXas6kNg3tL1PLl0I6scAmadRi6BsA4Y\nmfW6KGlrkPzWPx0guVdweURsb9xH0uvAhcCjSfO9wFsR8YMjvXlE3Jv0o7S0NHKo11pYRPDGhp3J\nmcB7IXDe2AK+eWEJn54wlCEOAbMOL5dAWAiMk1RMJgiuAL6S3UFSAbAtIuqA28g8cYSkImBrROyT\ndAJwAfCvybz/BwwErmuhbbEWVB8C9fcEVm/dS143cW7JEIeAWSfVbCBERI2km4GnyTx2Oicilkma\nCZRHxFxgCnCHpCBzyejbyeKnAP+ctIvMk0VLk6C4HXgTeEUSwI8j4r6W3Tw7FvPf3Mw//H5ZQwic\nN3YIN0wey6cnDGNw3/y0yzOzVqKIjnMVprS0NMrLy9Muo1M7WFPH5H+aT68eeVx/UYlDwKwTkLQo\nIkqb6+e/VLbDPP7aOjbs2M/Pr/0Lpnz4xLTLMbM21C3tAqz9qK0L7n62kgknDWDyhwrTLsfM2pgD\nwRr857KNVFXv4cYpY0nu65hZF+JAMCDzVNFdZRUUF/TlklOHp12OmaXAgWAAPPfWFl5ft5MbLioh\nr5vPDsy6IgeCATCrrIKhA3py2Zkj0i7FzFLiQDBeeeddXqzaxjcvLKFn97y0yzGzlDgQjFnzKxnU\npwdXTvJ3RZl1ZQ6ELm7Fxl38YfkmZpw3hr49/WcpZl2ZA6GLu/vZSvrk5zHjvDFpl2JmKXMgdGFr\ntu1l7uL1fGXSKAb18ddTmHV1DoQu7N4FVXQTXHdhSdqlmFk74EDoojbv2s+vy9dw+ZlFDBvYK+1y\nzKwdcCB0UXP+tJqa2jpumDw27VLMrJ1wIHRBO/Yd4qEX3+aS04ZTXNA37XLMrJ1wIHRBD734NrsP\n1HCjzw7MLEtOgSBpqqQVkiok3drE/NGS/ihpiaSyZES0+vZXJL0maZmkb2Utc5akpck6fyh/vWab\n2Hewljl/WsXkDxVy6oiBaZdjZu1Is4EgKQ+4C7gEGA9cKWl8o253Ag9ExOnATOCOpH0DcG5ETATO\nBm6VdFIybzbwTWBc8jP1OLfFcvBI+Rq27jnITVN8dmBmh8vlDGESUBERVRFxEHgYmNaoz3jgmWR6\nfv38iDgYEQeS9p717ydpODAgIl6MzBieDwBfOK4tsWYdqq3j3gVVlI4+gUnFg9Mux8zamVwCYQSw\nJuv12qQt22JgejJ9GdBf0hAASSMlLUnW8Y8RsT5Zfm0z67QWNve19azbvo+bLvYAOGb2fi11U/kW\nYLKkV4HJwDqgFiAi1iSXkk4GrpE09GhWLOl6SeWSyqurq1uo3K6nri6Y/WwlHxnWn4s9VrKZNSGX\nQFgHjMx6XZS0NYiI9RExPSLOAG5P2rY37gO8DlyYLF/0QevMWu7eiCiNiNLCQo/ze6z+a/kmKjbv\n9vCYZnZEuQTCQmCcpGJJ+cAVwNzsDpIKJNWv6zZgTtJeJKl3Mn0CcAGwIiI2ADslnZM8XXQ18LsW\n2SJ7n4hg1vwKRg3uw2dP8/CYZta0ZgMhImqAm4GngeXAIxGxTNJMSZcm3aYAKyStBIYC30vaTwFe\nkrQYeBa4MyKWJvNuAu4DKoBK4KmW2SRr7PnKrSxeu4MbJpfQPc9/emJmTVPmIZ+OobS0NMrLy9Mu\no8P56n0vsnLTbp7724vp1cMjopl1NZIWRURpc/3862Int3jNdv5csZXrLih2GJjZB3IgdHKzyioY\n0Ks7Xz1ndNqlmFk750DoxCo27+LpZZu45rwx9PPwmGbWDAdCJza7rIpePbp5eEwzy4kDoZNat30f\nv3ttHVdOGsWQfj3TLsfMOgAHQif1kwVVSPBND49pZjlyIHRCW3Yf4OGF7/CFiSM4aVDvtMsxsw7C\ngdAJ/ezPqzhQU8e3/BXXZnYUHAidzK79h3jghbeZOmEYYwv7pV2OmXUgDoRO5qEX32HX/hpumnJy\n2qWYWQfjQOhE9h+q5ad/WsWF4wo4rcjDY5rZ0XEgdCK/WbSWLbsPcKPvHZjZMXAgdBI1tXXcu6CS\niSMHcW7JkLTLMbMOyIHQSTyxZANrtu3jJg+AY2bHyIHQCdTVBbPLKhl3Yj8+ccpRjVBqZtbAgdAJ\nPPPmZlZs2sVNF4+lWzefHZjZsckpECRNlbRCUoWkW5uYP1rSHyUtkVQmqShpnyjpBUnLknlfzlrm\n45JekfSapD9J8nOSxyAiuKusgqITevP5009Kuxwz68CaDQRJecBdwCXAeOBKSeMbdbsTeCAiTgdm\nAnck7XuBqyNiAjAV+IGkQcm82cBXI2Ii8Evg7453Y7qiF6u28eo727nhIg+PaWbHJ5cjyCSgIiKq\nIuIg8DAwrVGf8cAzyfT8+vkRsTIi3kqm1wObgcKkXwADkumBwPpj3YiubFZZBQX98vli6ci0SzGz\nDi6XQBgBrMl6vTZpy7YYmJ5MXwb0l3TYs4+SJgH5QGXSdB3wpKS1wFXA94+udFu6dgfPvbWFr3t4\nTDNrAS11jeEWYLKkV4HJwDqgtn6mpOHAg8C1EVGXNP818JmIKAJ+BvxLUyuWdL2kcknl1dXVLVRu\n5zD72Qr69+zO1zw8ppm1gFwCYR2QfT2iKGlrEBHrI2J6RJwB3J60bQeQNACYB9weES8mbYXARyPi\npWQVvwbOa+rNI+LeiCiNiNLCwsKmunRJldW7eer1jVx17mgG9OqRdjlm1gnkEggLgXGSiiXlA1cA\nc7M7SCqQVL+u24A5SXs+8BiZG86PZi3yLjBQ0oeS158Elh/7ZnQ99zxbSX5eN75+QXHapZhZJ9Hs\nyOsRUSPpZuBpIA+YExHLJM0EyiNiLjAFuENSAAuAbyeLfwm4CBgiaUbSNiMiXpP0TeC3kurIBMTX\nW3C7OrUNO/bx2KuZ4TELPDymmbUQRUTaNeSstLQ0ysvL0y4jdTN//wb3v7CaslumMHJwn7TLMbN2\nTtKiiChtrp8fXO9gtu05yK9efodpE09yGJhZi3IgdDA/f341+w7VcuNkf8W1mbUsB0IHsvtADT//\n8yo+NX4o44b2T7scM+tkHAgdyC9fepud+2u46WJ/7ZOZtTwHQgdxoKaW+55bxXljhzBx5KDmFzAz\nO0oOhA7it4vWsXnXAW6a4rMDM2sdDoQOoKa2jnsWVHJ60UDOP9nDY5pZ63AgdABPvr6Rt7fu9fCY\nZtaqHAjtXERmeMyxhX351PhhaZdjZp2YA6GdK1tRzfINO/nWZA+PaWaty4HQzs0qq+Ckgb2YNrHx\nEBRmZi3LgdCOvbxqGwtXv8v1F5WQ393/q8ysdfko047NKqtgSN98vvwXo9Iuxcy6AAdCO7Vs/Q7K\nVlRz7flj6J3v4THNrPU5ENqp2WWV9OvZnavOHZN2KWbWRTgQ2qHVW/bw5NINfPWcUQzs7eExzaxt\nOBDaoXsWVNI9rxvf8PCYZtaGcgoESVMlrZBUIenWJuaPlvRHSUsklUkqStonSnpB0rJk3pezlpGk\n70laKWm5pL9quc3quDbt3M9vF63ji2cVcWL/XmmXY2ZdSLNjKkvKA+4CPgmsBRZKmhsRb2R1uxN4\nICLul/Qx4A7gKmAvcHVEvCXpJGCRpKcjYjswAxgJfCQi6iSd2KJb1kHd91wVNXV13HCRB8Axs7aV\nyxnCJKAiIqoi4iDwMDCtUZ/xwDPJ9Pz6+RGxMiLeSqbXA5uBwqTfjcDMiKhL5m8+ng3pDLbvPcgv\nXnqHz3/0JEYN8fCYZta2cgmEEcCarNdrk7Zsi4HpyfRlQH9Jh30tp6RJQD5QmTSNBb4sqVzSU5LG\nNfXmkq5P+pRXV1fnUG7Hdf/zb7P3YC03TvHZgZm1vZa6qXwLMFnSq8BkYB1QWz9T0nDgQeDa+jMC\noCewPyJKgZ8Ac5pacUTcGxGlEVFaWFjYVJdOYc+BGn72/Co+ccqJfGTYgLTLMbMuqNl7CGQO7iOz\nXhclbQ2Sy0HTAST1Ay5P7hMgaQAwD7g9Il7MWmwt8O/J9GPAz45lAzqLX738Dtv3HuJGD4BjZinJ\n5QxhITBOUrGkfOAKYG52B0kFkurXdRvJb/tJ/8fI3HB+tNF6HwcuTqYnAyuPbRM6vvrhMc8uHsxZ\no09Iuxwz66KaDYSIqAFuBp4GlgOPRMQySTMlXZp0mwKskLQSGAp8L2n/EnARMEPSa8nPxGTe94HL\nJS0l81TSdS21UR3N46+uY+PO/dx0sc8OzCw9ioi0a8hZaWlplJeXp11Gi6qtCz7xL8/SJz+PJ/7b\nBR4RzcxanKRFyf3aD+S/VE7Zf7y+kVVb9nDTlJMdBmaWKgdCiiKCWWUVlBT0ZeqpHh7TzNLlQEjR\ngre2sGz9Tm6YXEKeh8c0s5Q5EFI0a34Fwwb04rIzitIuxczMgZCWRW+/y0urtnHdhcUeHtPM2gUf\niVIyu6yCQX16cOUkD49pZu2DAyEFb27cyR+Wb+ba84rp2zOXPxY3M2t9DoQUzC6rpG9+HtecNzrt\nUszMGjgQ2tg7W/fy+8Xr+crZoxjUJz/tcszMGjgQ2tg9Cyrp3q0b111YknYpZmaHcSC0oc279vOb\nRWu5/KwRDB3g4THNrH1xILShn/5pFTW1Hh7TzNonB0Ib2bHvEL948R0+c9pwxhT0TbscM7P3cSC0\nkQdfWM3uAzUeHtPM2i0HQhvYd7CWOX9ezZQPFzLhpIFpl2Nm1iQHQhv49cJ32LbnIDd5eEwza8dy\nCgRJUyWtkFQh6dYm5o+W9EdJSySVSSpK2idKekHSsmTel5tY9oeSdh//prRPB2vquHdBFaWjT2BS\n8eC0yzEzO6JmA0FSHnAXcAkwHrhS0vhG3e4kM27y6cBMMkNiAuwFro6ICcBU4AeSBmWtuxTo1IMI\n/+61dazfsZ9ve3hMM2vncjlDmARURERVRBwEHgamNeozHngmmZ5fPz8iVkbEW8n0emAzUAgNQfNP\nwN8e70a0V3V1wd3PVnLK8AFM+XBh2uWYmX2gXAJhBLAm6/XapC3bYmB6Mn0Z0F/SkOwOkiYB+UBl\n0nQzMDciNhxt0R3Ff76xkcrqPdw4ZayHxzSzdq+lbirfAkyW9CowGVgH1NbPlDQceBC4NiLqJJ0E\nfBH4UXMrlnS9pHJJ5dXV1S1UbuvLDI9ZyeghffiMh8c0sw4gl0BYB4zMel2UtDWIiPURMT0izgBu\nT9q2A0gaAMwDbo+IF5NFzgBOBiokrQb6SKpo6s0j4t6IKI2I0sLCjnPZ5c8VW1mydgc3XDSW7nl+\nmMvM2r9cvox/ITBOUjGZILgC+Ep2B0kFwLaIqANuA+Yk7fnAY2RuOD9a3z8i5gHDspbfHRGd6q7r\nrLIKTuzfk8vPanx1zcysfWr2V9eIqCFzvf9pYDnwSEQskzRT0qVJtynACkkrgaHA95L2LwEXATMk\nvZb8TGzpjWhvXluznecrt3LdhcX07J6XdjlmZjlRRKRdQ85KS0ujvLw87TKadf0D5by0aht/vvVj\n9POIaGaWMkmLIqK0uX6+uN3C3tq0i/98YxPXnDvaYWBmHYoDoYXNLqukd488ZpxfnHYpZmZHxYHQ\ngtZs28vvFq/nykmjGNzXw2OaWcfiQGhBP3muim6Cb17kswMz63gcCC2ketcBfr1wDZedMYLhA3un\nXY6Z2VFzILSQn/15FQdr67hhsgfAMbOOyYHQAnbuP8SDL7zNJacOY2xhv7TLMTM7Jg6EFvDQi2+z\n60CNB8Axsw7NgXCc9h+qZc6fVnHhuAJOHeHhMc2s43IgHKfflK9hy24Pj2lmHZ8D4Tgcqq3jngVV\nnDFqEOeUeHhMM+vYHAjH4feL17P23X3cNOVkD4BjZh2eA+EY1dUFs8sq+dDQfnz8IyemXY6Z2XFz\nIByjPyzfxFubd3PTlJPp1s1nB2bW8TkQjkH98JgjB/fmc6cPT7scM7MW4UA4Bi9UbeW1Ndu53sNj\nmlknktPRTNJUSSskVUi6tYn5oyX9UdISSWWSipL2iZJekLQsmfflrGV+kazzdUlzJPVouc1qXbPL\nKino15MvnlWUdilmZi2m2UCQlAfcBVwCjAeulDS+Ubc7yYybfDowE7gjad8LXB0RE4CpwA8kDUrm\n/QL4CHAa0Bu47ji3pU0sXbuD597awjcuKKZXDw+PaWadRy5nCJOAioioioiDwMPAtEZ9xgPPJNPz\n6+dHxMqIeCuZXg9sBgqT109GAngZ6BC/bs8qq6B/r+587ZxRaZdiZtaicgmEEcCarNdrk7Zsi4Hp\nyfRlQH9JQ7I7SJoE5AOVjdp7AFcB/5F72emo2Lyb/1i2kavPHU3/Xh3mCpeZWU5a6o7oLcBkSa8C\nk4F1QG39TEnDgQeBayOirtGys4AFEfFcUyuWdL2kcknl1dXVLVTusbnn2Ury87pxrYfHNLNOKJdA\nWAeMzHpdlLQ1iIj1ETE9Is4Abk/atgNIGgDMA26PiBezl5P092QuIX3nSG8eEfdGRGlElBYWFuZQ\nbutYt30fj726jiv+YiQF/XqmVoeZWWvJJRAWAuMkFUvKB64A5mZ3kFQgqX5dtwFzkvZ84DEyN5wf\nbbTMdcCngSubOGtod36yoAqAb15UknIlZmato9lAiIga4GbgaWA58EhELJM0U9KlSbcpwApJK4Gh\nwPeS9i8BFwEzJL2W/ExM5t2d9H0haf9ui21VC9u6+wAPL3yHaRNHUHRCn7TLMTNrFd1z6RQRTwJP\nNmr7btb0o8CjTSz3EPDQEdaZ03u3Bz9/fjUHauq4cYrPDsys8/Kf2TZj1/5D3P/8aj41fignn9g/\n7XLMzFqNA6EZv3zpHXbu9/CYZtb5ORA+wP5Dtdz3p1Wcf/IQPjpyUPMLmJl1YA6ED/DbV9ZSveuA\nzw7MrEtwIBxBTW0d9zxbxUeLBnLe2CHNL2Bm1sE5EI5g3tINvLNtLzd6eEwz6yIcCE2IyAyPefKJ\n/fjU+KFpl2Nm1iYcCE145s3NvLlxF9+aPNbDY5pZl+FAaKR+eMwRg3ozbeJJaZdjZtZmHAiNvLxq\nG4vefpfrLyqhh4fHNLMuxEe8RmaVVTKkbz5fKh3ZfGczs07EgZDl9XU7eHZlNV+/oJje+R4e08y6\nFgdCltnPVtKvZ3e+ds7otEsxM2tzDoTEqi17eGrpBr52zmgG9vbwmGbW9TgQEvc8W0n3vG58/YIx\naZdiZpYKBwKwccd+fvvKWr5UWsSJ/XulXY6ZWSpyCgRJUyWtkFQh6dYm5o+W9EdJSySVSSpK2idK\nekHSsmTel7OWKZb0UrLOXyfDbabiJ89VURdww0Vj0yrBzCx1zQaCpDzgLuASYDxwpaTxjbrdSWbc\n5NOBmcAdSfte4OqImABMBX4gqf57pP8R+NeIOBl4F/jG8W7MsXh3z0F+9fI7fP704Ywc7OExzazr\nyuUMYRJQERFVEXEQeBiY1qjPeOCZZHp+/fyIWBkRbyXT64HNQKEy3xb3Md4bdvN+4AvHsyHH6ufP\nr2bvwVpu9Fdcm1kXl0sgjADWZL1em7RlWwxMT6YvA/pLOuw7oyVNAvKBSmAIsD0iaj5gna1uz4Ea\nfv78aj5xyol8eJiHxzSzrq2lbirfAkyW9CowGVgH1NbPlDQceBC4NiLqjmbFkq6XVC6pvLq6uoXK\nzfjVy++wY98hbrrYZwdmZrkEwjog+3scipK2BhGxPiKmR8QZwO1J23YASQOAecDtEfFisshWYJCk\n7kdaZ9a6742I0ogoLSwszHGzmnegppafPFfFOSWDOXPUCS22XjOzjiqXQFgIjEueCsoHrgDmZneQ\nVCCpfl23AXOS9nzgMTI3nOvvFxARQeZew18mTdcAvzueDTlaj72yjk07PTymmVm9ZgMhuc5/M/A0\nsBx4JCKWSZop6dKk2xRghaSVwFDge0n7l4CLgBmSXkt+Jibz/ifwHUkVZO4p/LSlNqo5tXXBPQuq\nOHXEAC5yXyJyAAAFjElEQVQcV9BWb2tm1q51b74LRMSTwJON2r6bNf0o7z0xlN3nIeChI6yziswT\nTG3uqdc3sGrLHmZ99UwPj2lmluhyf6kcEcyaX0lJQV8+PWFY2uWYmbUbXS4QylZW88aGnXxr8ljy\nPDymmVmDLhcIs+dXMnxgL75wRpv/2YOZWbvWpQKhfPU2Xl69jesuLCG/e5fadDOzZnWpo+KsskpO\n6NODKyd5eEwzs8a6TCAs37CTZ97czLXnF9MnP6eHq8zMupQuEwizyyrpm5/HNeeOSbsUM7N2qUsE\nwttb9/DEkvV89ZzRDOzj4THNzJrSJQLhngVVdO/WjW9cUJx2KWZm7VaXCIRRg/vwjQuLGTrAw2Oa\nmR1Jl7i7+q3JHhrTzKw5XeIMwczMmudAMDMzwIFgZmYJB4KZmQEOBDMzSzgQzMwMcCCYmVnCgWBm\nZgAoItKuIWeSqoG3j3HxAmBLC5bTUlzX0XFdR8d1HZ3OWtfoiChsrlOHCoTjIak8IkrTrqMx13V0\nXNfRcV1Hp6vX5UtGZmYGOBDMzCzRlQLh3rQLOALXdXRc19FxXUenS9fVZe4hmJnZB+tKZwhmZvYB\nOl0gSJoqaYWkCkm3NjG/p6RfJ/NfkjSmndQ1Q1K1pNeSn+vaoKY5kjZLev0I8yXph0nNSySd2do1\n5VjXFEk7svbVd9uorpGS5kt6Q9IySf+9iT5tvs9yrKvN95mkXpJelrQ4qesfmujT5p/HHOtq889j\n1nvnSXpV0hNNzGvd/RURneYHyAMqgRIgH1gMjG/U5ybg7mT6CuDX7aSuGcCP23h/XQScCbx+hPmf\nAZ4CBJwDvNRO6poCPJHCv6/hwJnJdH9gZRP/H9t8n+VYV5vvs2Qf9EumewAvAec06pPG5zGXutr8\n85j13t8BftnU/6/W3l+d7QxhElAREVURcRB4GJjWqM804P5k+lHg45LUDupqcxGxANj2AV2mAQ9E\nxovAIEnD20FdqYiIDRHxSjK9C1gOjGjUrc33WY51tblkH+xOXvZIfhrftGzzz2OOdaVCUhHwWeC+\nI3Rp1f3V2QJhBLAm6/Va3v/BaOgTETXADmBIO6gL4PLkMsOjkka2ck25yLXuNJybnPI/JWlCW795\ncqp+BpnfLrOlus8+oC5IYZ8llz9eAzYD/xURR9xfbfh5zKUuSOfz+APgb4G6I8xv1f3V2QKhI/s9\nMCYiTgf+i/d+C7D3e4XMn+J/FPgR8HhbvrmkfsBvgf8RETvb8r0/SDN1pbLPIqI2IiYCRcAkSae2\nxfs2J4e62vzzKOlzwOaIWNTa73UknS0Q1gHZSV6UtDXZR1J3YCCwNe26ImJrRBxIXt4HnNXKNeUi\nl/3Z5iJiZ/0pf0Q8CfSQVNAW7y2pB5mD7i8i4t+b6JLKPmuurjT3WfKe24H5wNRGs9L4PDZbV0qf\nx/OBSyWtJnNZ+WOSHmrUp1X3V2cLhIXAOEnFkvLJ3HSZ26jPXOCaZPovgWciuUOTZl2NrjNfSuY6\ncNrmAlcnT86cA+yIiA1pFyVpWP11U0mTyPw7bvWDSPKePwWWR8S/HKFbm++zXOpKY59JKpQ0KJnu\nDXwSeLNRtzb/POZSVxqfx4i4LSKKImIMmWPEMxHxtUbdWnV/dW+pFbUHEVEj6WbgaTJP9syJiGWS\nZgLlETGXzAfnQUkVZG5cXtFO6vorSZcCNUldM1q7Lkm/IvP0SYGktcDfk7nBRkTcDTxJ5qmZCmAv\ncG1r15RjXX8J3CipBtgHXNEGoQ6Z3+CuApYm158B/hcwKqu2NPZZLnWlsc+GA/dLyiMTQI9ExBNp\nfx5zrKvNP49H0pb7y3+pbGZmQOe7ZGRmZsfIgWBmZoADwczMEg4EMzMDHAhmZpZwIJiZGeBAMDOz\nhAPBzMwA+P++QqXLZRhinwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2183005f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(overall_accs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sentence accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VPW9//HXh0ASQgKBJIQlQAgJm4qgERTFBVGx7YX2\nZ3vFVqutLbe29N7W21ru7e/R3p/9LS7dXa7S1nu7e9VutBdEFFwqoKDgwj4JSxKQhD0QEkjy+f0x\nQzqEbQLJnEzm/Xw8eDDnnO9kPjkw7++Zc77zPebuiIhIcugWdAEiIhI/Cn0RkSSi0BcRSSIKfRGR\nJKLQFxFJIgp9EZEkotAXEUkiCn0RkSSi0BcRSSLdgy6gtdzcXC8sLAy6DBGRhPLWW2/tdve8s7Xr\ndKFfWFjIqlWrgi5DRCShmNm2WNrp9I6ISBJR6IuIJBGFvohIElHoi4gkEYW+iEgSUeiLiCQRhb6I\nSBLpdOP0RSSxuTuh6kOsKN9DU7NTkp9FSX4meZlpmFnQ5SU9hb6InLeKvXW8HtrNsrI9LCvbw+5D\nDSe1yc7owcj+4Q6gpH8mI/OzKMnPIjczVZ1BHCn0RaTNdh2sZ3nZHpaVhYO+ct8RAPKy0riyOIfJ\nI3K4oiiX9NRubN51iE27atm06xCbd9Xy53d2cLC+seVn9c3oEf400NIRhP/OzUwL6tfr0hT6InJW\n+w4f5Y0te3g9FA76sprDAPTp2YMrinKYfXURk0fkMCIv86Sj9v5Z6VxZnNuy7O7U1DawKdIZbK6u\nZfOuQyd1Bv16pVLcP5ORkU6gJPIpQZ3B+VHoi8hJDjU0snLL3pYj+XU7D+IOGakpTBzej1svG8Lk\nEbmMGdiblG5tOzVjZvTvnU7/3ulcVXJiZ1Bd29DyqSBUHf77T2t2UNuqMzj+qWBkfibF/cN/56gz\niIlCX0SoP9bE29v3sSxyJP9O5QGamp3UlG5cOqwv904byeTiHMYVZNMjpWMG/ZkZ+b3Tye+dzpSS\nv00W6e7sOtgQ+VQQPkW0aVctf1xdRW3D3zqDnF6pkesF4U6gJD+LkflZ9OuV2iH1JiqFvkgSOtbU\nzLuVB1geOZJftW0fRxubSelmjCvowxeuKWLyiFwuHdaX9B4pgdZqZgzok86APulcPfLUncGmXeFT\nRJuqT+4McjOPnyYKXzgeGXncN0k7A4W+SBJobnbW7TzYcvH1zS17OXy0CYCxA3vz6cuHMbk4h8sK\n+5GV3iPgamNzps7gg4P1LReOj39C+P3bVRxq1RlEfyooSZLOQKEv0gW5O2U1h1uO5JeX72F/3TEA\nivJ68bFLBjN5RC6XF+V0udMfZsbAPj0Z2Kcn17TqDHYeqG/5VLA5cs3gdyd1BmktF4+Lo64dZGd0\njf2k0BfpIir21p0wjLK6NjxWfnB2T24Yk8/k4vAwygF90gOuNBhmxqDsngzK7sm1o/q3rHd3dkQ6\ng9Dx4aXVh3h2VUXLpyEID0dtPax0ZP8s+mQkxiej4xT6IgmqujY8Vn555AtR2/fWAeHTFleMyGXy\niByuHJHLkH499eWnMzAzBmf3ZHB2T647TWewOep7Bs+sqqCuVWcwsuUCclbL487aGSj0RRLE/rqj\nrCjf23LKZnP1IQB6p3fn8qIcPntlIZOLcynpf/JYeWm703UGzc3OjgNHTvjSWaj65M6gf1baCZ8K\nSvqHrx306RlsZ6DQF+mkDjc0snLr3sjUBrtZuyM8Vr5nj/BY+Y9fWsDkEbmMHdT2sfJy7rp1Mwr6\nZlDQN4PrRp/YGVTtP9JyreD4dYOn36zgyLG/dQb5vdNOul5Q3D9+nYG5+9kbmU0HfgSkAD919wda\nbb8X+BzQCNQAn3X3bZFtTcB7kabb3X3GmV6rtLTUdWN0SUb1x5pYvX1/y5H8mor9NEbGyk8Yms3k\nEblMLs7h4oJsUrtrgtxE0bozOH4hOVR96ITOYEDky2rf/cTF5/Q6ZvaWu5eerd1Zj/TNLAV4DLgB\nqARWmtl8d18X1Ww1UOrudWZ2D/AQcGtk2xF3H9/m30Cki2tsaua9qgMtR/Krtu6jobGZbgYXFWRH\npjYIj5XvmRrsWHk5d926GUP6ZTCkXwZTR+e3rD/eGUTPS9Q7DsNlYzm9MxEIuXs5gJk9DcwEWkLf\n3ZdGtV8B3N6eRYp0Bc3NzoYPallWtpvlZXt4Y8velqGCowdk8alJw5g8IoeJRf3i8uaXYEV3BteP\nyT/7E9pJLKE/GKiIWq4EJp2h/d3AwqjldDNbRfjUzwPu/sc2VymSgNydLbsPtxzJLy/bw77jY+Vz\nezFz/KDIWPl+mjdG4qZdL+Sa2e1AKXBN1Oph7l5lZkXAEjN7z93LWj1vNjAbYOjQoe1ZkkhcVe0/\nwrLQ7pZhlB8crAdgYJ90po7OZ/KIHCYX5zCwT8+AK5VkFUvoVwFDopYLIutOYGbTgG8C17h7yx0U\n3L0q8ne5mb0MTABOCH13nwfMg/CF3Lb9CiLBqaltYHn5npaLr9v2hMfK5/RK5YoROeGLryNyGJaT\noWGU0inEEvorgRIzG0447GcBn4xuYGYTgCeB6e5eHbW+L1Dn7g1mlgtcSfgir0hCOnDkGG+Uh4/i\nl5ftYeOuWgCy0rozqSiHO68oZHJxDqPysxTy0imdNfTdvdHM5gCLCA/ZfMrd15rZ/cAqd58PPAxk\nAs9G/qMfH5o5BnjSzJoJ34T9gVajfkQ6PXfnlU01/PvLZazcupdmh/Qe3bissB8fnTCYySNyuGBQ\nb7p30JTDIu0ppnH68aRx+tJZNDc7i9fv4tElId6rOsDg7J7ccmkBV47IYfzQbNK6axildB7tNk5f\nJNk0NTsL3tvJY0tDbPiglmE5GTx0yzg+OmGwvhQlCU+hLxLR2NTMn9bs4LGXQ5TXHKa4fyY/vHU8\nHxk3UKdupMtQ6EvSa2hs4vdvV/H4yyEq9h5hzMDePP6pS5h+wQC6aU4b6WIU+pK06o818V8rK3ji\nlTJ2Hqjn4oI+fPsjF3D9mP4aeSNdlkJfks7hhkZ+88Z25r1WTk1tA5cV9uXBW8YxpSRXYS9dnkJf\nksbB+mP8cvk2fvpaOfvqjnFVcS6P3jaBSUU5QZcmEjcKfeny9tcd5anXt/Kfr2/hYH0jU0f3Z87U\nYi4Z2jfo0kTiTqEvXdbuQw385LVyfrV8G4ePNjH9ggHMmVrMhYP7BF2aSGAU+tLlfHCgnidfLeO3\nb27naGMzHxk3iDlTixmZnxV0aSKBU+hLl1Gxt44nXinj2VWVNLnzsQmD+eK1IyjKywy6NJFOQ6Ev\nCW/L7sM8vjTEH1ZX0c2Mj5cWcM81IxjSLyPo0kQ6HYW+JKxNu2p5bGmIP7+zgx4p3bjjimHMvrpI\nc9WLnIFCXxLO+1UHeGxpiIXvf0BGagqfn1LE56YUkZelu0+JnI1CXxLG6u37eHRJiJc2VJOV3p1/\nnFrMZ64cTt9eqUGXJpIwFPrS6b1RvodHloT4a2g32Rk9+NqNI7njikL69NTNw0XaSqEvnZK789fQ\nbh55KcSbW/eSm5nGv35oNJ+aNIxeafpvK3Ku9O6RTsXdWbKhmkeWhFhTsZ8BvdP5t78by6yJQ0nv\noZuWiJwvhb50Cs3NzvNrP+CRJSHW7zxIQd+e/N+PXcQtlw7WHapE2pFCXwLV2NTMX94N36Vqc/Uh\ninJ78d1PXMzM8YPooRuXiLQ7hb4E4lhTM3+I3Lhk6546RuZn8uPbJvDhiwaSohuXiHSYmELfzKYD\nPwJSgJ+6+wOttt8LfA5oBGqAz7r7tqjtvYF1wB/dfU471S4JqP5YE8++VckTL5dRtf8IFw7uzRO3\nX8qNY/N1lyqRODhr6JtZCvAYcANQCaw0s/nuvi6q2Wqg1N3rzOwe4CHg1qjt3wFebb+yJdEcOdrE\nb97czrxXy9h1sIEJQ7P53x+9kGtH5enGJSJxFMuR/kQg5O7lAGb2NDCT8JE7AO6+NKr9CuD24wtm\ndimQDzwPlLZDzZJADjU0tty4ZM/ho1xe1I/v//14Jo/IUdiLBCCW0B8MVEQtVwKTztD+bmAhgJl1\nA75HuBOYdo41SgI6UHeM/1y2lade38KBI8e4emQeX55azGWF/YIuTSSpteuFXDO7nfDR/DWRVV8E\nFrh75ZmO6sxsNjAbYOjQoe1ZksTZnkMNPPX6Fn6xbBu1DY1MG5PPnKnFjB+SHXRpIkJsoV8FDIla\nLoisO4GZTQO+CVzj7g2R1VcAU8zsi0AmkGpmh9x9bvRz3X0eMA+gtLTU2/xbSOCqD9Yz79Vyfv3G\nduobm/jQhQP50nXFjB3UO+jSRCRKLKG/Eigxs+GEw34W8MnoBmY2AXgSmO7u1cfXu/unotrcRfhi\n7wmBL4ltx/4jPPFKGU+vrKCxqZmZ48M3LinRXapEOqWzhr67N5rZHGAR4SGbT7n7WjO7H1jl7vOB\nhwkfyT8bOY2z3d1ndGDdErDte+p4/OUQv3u7Ene45ZIC7rl2BIW5vYIuTUTOwNw719mU0tJSX7Vq\nVdBlyGmEqg/x+NIQf3pnByndjFtLh/CFa0cwOFs3LhEJkpm95e5nHSGpb+RKTNbvPMijS0MseG8n\nad27cdfkQmZfXUR+7/SgSxORNlDoyxm9W7mfR5aEWLxuF71SU/jCNSP43FXDycnUXapEEpFCX05p\n1da9PLIkxCubauid3p2vTCvhrsmFZGfoLlUiiUyhLy3cneVl4btULS/fQ79eqdw3fRR3XD6MrHTd\npUqkK1DoC+7Oy5tqeHRJiLe27aN/Vhr/88Nj+OSkoWSk6r+ISFeid3QSa252Fq/fxaNLQrxXdYBB\nfdL5zswL+ETpEN2lSqSLUugnqaONzcyat5y3t+9naL8MHrzlIj42oYDU7rpxiUhXptBPUr95Yxtv\nb9/Pv/3dWG6/fBjddZcqkaSg0E9CtfXH+PGSEFcU5XDn5EJNcSySRHR4l4R+8mo5ew8fZe7NoxX4\nIklGoZ9kqmvr+clrW/jwuIFcrOmORZKOQj/J/PilzRxrauZrN44KuhQRCYBCP4mU1xzit29WcNvE\noQzXbJgiSUmhn0S+98Im0rp348vXFwddiogERKGfJNZU7Oe/39vJ56YU0T9LM2OKJCuFfhJwdx5Y\nuJ6cXql8fsrwoMsRkQAp9JPAK5tqWFG+ly9PLdbEaSJJTqHfxTU1Ow8s3MDQfhl8ctKwoMsRkYAp\n9Lu4P62pYsMHtXztplGaV0dEFPpdWf2xJr73wiYuHNybj1w0MOhyRKQTiCn0zWy6mW00s5CZzT3F\n9nvNbJ2ZvWtmL5nZsMj6YWb2tpmtMbO1ZvaF9v4F5PR+tWIbVfuPMHf6GLp103QLIhJD6JtZCvAY\ncDMwFrjNzMa2arYaKHX3ccBzwEOR9TuBK9x9PDAJmGtmg9qreDm9g/XHeHRpiCkluVxVkht0OSLS\nScRypD8RCLl7ubsfBZ4GZkY3cPel7l4XWVwBFETWH3X3hsj6tBhfT9rBk6+Usb/uGN+YPjroUkSk\nE4klhAcDFVHLlZF1p3M3sPD4gpkNMbN3Iz/jQXffcS6FSux2HaznZ3/dwoyLB3Hh4D5BlyMinUi7\nHnmb2e1AKfDw8XXuXhE57VMM3Glm+ad43mwzW2Vmq2pqatqzpKT0wxc309TsmlRNRE4SS+hXAUOi\nlgsi605gZtOAbwIzok7ptIgc4b8PTDnFtnnuXurupXl5ebHWLqcQqj7EM6sq+NSkYQzNyQi6HBHp\nZGIJ/ZVAiZkNN7NUYBYwP7qBmU0AniQc+NVR6wvMrGfkcV/gKmBjexUvJ3t40QZ69kjhy1M1qZqI\nnOyst0t090YzmwMsAlKAp9x9rZndD6xy9/mET+dkAs9G7sS03d1nAGOA75mZAwZ8193f66DfJem9\ntW0fi9bu4t4bRpKTmRZ0OSLSCcV0j1x3XwAsaLXuW1GPp53meYuBcedToMTG3Xlw4QZyM9O4+ypN\nqiYip6YhlF3Ekg3VvLl1L/80rYReabrfvYicmkK/C2hqdh58fgOFORnMumzI2Z8gIklLod8F/P7t\nSjbtOsTXbxpNjxT9k4rI6SkhElz9sSa+v3gTFxf04UMXDQi6HBHp5BT6Ce7ny7ay80A9c28eQ2Tk\nlIjIaSn0E9iBumM8tjTEtaPyuGJETtDliEgCUOgnsMdfCVHb0Mh9N2lSNRGJjUI/Qe3Yf4T/eH0r\nHxs/mLGDegddjogkCIV+gvrhi5vA4as3jAy6FBFJIAr9BLRpVy3PvVXJHVcMY0g/TaomIrFT6Ceg\nh57fSK/U7nzpOk2qJiJto9BPMCu37uXF9bv4wrUj6NcrNehyRCTBKPQTiLvzwMIN9M9K47NXalI1\nEWk7hX4CeWHdLt7ato+v3jCSnqkpQZcjIglIoZ8gGpuaeej5DRTl9eITlxYEXY6IJCiFfoJ47q1K\nymoOc99No+muSdVE5BwpPRLAkaNN/ODFTUwYms1NF5x0X3kRkZgp9BPAfyzbwq6DDcydPlqTqonI\neVHod3L7Dh/l318u4/rR/ZlUpEnVROT8KPQ7ucdfDnGooZH7pmtSNRE5fzGFvplNN7ONZhYys7mn\n2H6vma0zs3fN7CUzGxZZP97MlpvZ2si2W9v7F+jKKvfV8fNl27jlkgJGDcgKuhwR6QLOGvpmlgI8\nBtwMjAVuM7OxrZqtBkrdfRzwHPBQZH0d8Gl3vwCYDvzQzLLbq/iu7vuLN4HBvZpUTUTaSSxH+hOB\nkLuXu/tR4GlgZnQDd1/q7nWRxRVAQWT9JnffHHm8A6gG8tqr+K5s/c6D/GF1FZ+ZXMig7J5BlyMi\nXUQsoT8YqIharoysO527gYWtV5rZRCAVKGtLgcnqoec3kJXWnXuuHRF0KSLShXRvzx9mZrcDpcA1\nrdYPBH4J3Onuzad43mxgNsDQoUPbs6SEtLxsD0s31jD35tFkZ2hSNRFpP7Ec6VcBQ6KWCyLrTmBm\n04BvAjPcvSFqfW/gv4FvuvuKU72Au89z91J3L83LS+6zP+7OA89vYEDvdO6aXBh0OSLSxcQS+iuB\nEjMbbmapwCxgfnQDM5sAPEk48Kuj1qcCfwB+4e7PtV/ZXdfz73/AOxX7ufeGkaT30KRqItK+zhr6\n7t4IzAEWAeuBZ9x9rZndb2YzIs0eBjKBZ81sjZkd7xT+HrgauCuyfo2ZjW//X6NrONbUzMOLNlLS\nP5P/ccmZLpuIiJybmM7pu/sCYEGrdd+KejztNM/7FfCr8ykwmTyzqoLy3Yf5yadLNamaiHQIJUsn\nUXe0kR++uJnLCvsybUz/oMsRkS5Kod9J/Oy1LdTUNjD3Zk2qJiIdR6HfCew51MCTr5Zz49h8Lh3W\nL+hyRKQLU+h3Ao8uDVF3tJH7po8KuhQR6eIU+gGr2FvHr1Zs4+9Lh1DcX5OqiUjHUugH7HsvbKSb\nGV+ZpknVRKTjKfQD9H7VAf64ZgefvWo4A/qkB12OiCQBhX6AHlq0keyMHnzhGk2qJiLxodAPyOuh\n3by6qYY51xXTp2ePoMsRkSSh0A9Ac7PzwMINDM7uye2XDwu6HBFJIgr9APz3ezt5r+qAJlUTkbhT\n6MfZ0cZmvvvCRkYPyOKjEzSpmojEl0I/zp5euZ1te+r4xvTRpHTTdAsiEl8K/Tg61NDIj1/azKTh\n/bh2VHLfLEZEgqHQj6OfvlbO7kNHNamaiARGoR8nNbUN/OTVcm6+cAAThvYNuhwRSVIK/Th5dMlm\n6hub+fpNmlRNRIKj0I+DrbsP8+s3tjPrsiEU5WUGXY6IJDGFfhx894WN9Ejpxj9dXxJ0KSKS5BT6\nHezdyv385d2dfG7KcPr31qRqIhKsmELfzKab2UYzC5nZ3FNsv9fM1pnZu2b2kpkNi9r2vJntN7O/\ntGfhicA9PN1C34wezL66KOhyRETOHvpmlgI8BtwMjAVuM7OxrZqtBkrdfRzwHPBQ1LaHgTvap9zE\n8trm3Swr28OXp5aQla5J1UQkeLEc6U8EQu5e7u5HgaeBmdEN3H2pu9dFFlcABVHbXgJq26nehHF8\nUrWCvj351OVDgy5HRASILfQHAxVRy5WRdadzN7CwLUWY2WwzW2Vmq2pqatry1E7rz+/uYN3Og3zt\nxlGkddekaiLSObTrhVwzux0oJXxKJ2buPs/dS929NC8v8acnaGhs4uFFGxk7sDczLh4UdDkiIi26\nx9CmChgStVwQWXcCM5sGfBO4xt0b2qe8xPTrFdup3HeEX3z2IrppUjUR6URiOdJfCZSY2XAzSwVm\nAfOjG5jZBOBJYIa7V7d/mYnjYP0xHlmymSuLc5hSkht0OSIiJzhr6Lt7IzAHWASsB55x97Vmdr+Z\nzYg0exjIBJ41szVm1tIpmNlrwLPA9WZWaWY3tftv0Yn85NVy9tUd4xvTNamaiHQ+sZzewd0XAAta\nrftW1ONpZ3julHOuLsFUH6znp69t4SPjBjKuIDvockRETqJv5LajH720mWNNzXztRk2qJiKdk0K/\nnZTXHOLplRV8ctJQCnN7BV2OiMgpKfTbyXdf2Eha9258eaomVRORzkuh3w5Wb9/Hgvc+4PNTisjL\nSgu6HBGR01Lon6fjk6rlZqbyeU2qJiKdnEL/PL28sYY3tuzlH68vITMtpsFQIiKBUeifh6Zm58Hn\nNzAsJ4NZl2lSNRHp/BT65+GPq6vY8EEtX7txFKndtStFpPNTUp2j+mNNfH/xJi4a3IcPXzQw6HJE\nRGKi0D9Hv1qxjar9R5h782hNqiYiCUOhfw4OHDnGo0tDTCnJ5cpiTaomIolDoX8OnnyljP2RSdVE\nRBKJQr+NPjhQz1Ovb+Gj4wdx4eA+QZcjItImCv02+uGLm2hqdv5Zk6qJSAJS6LdBqLqWZ1ZVcPvl\nwxjSLyPockRE2kyh3wYPPb+RjNTuzLmuOOhSRETOiUI/Rm9t28sL63bxD1cXkZOpSdVEJDEp9GPw\nt0nV0rh7yvCgyxEROWcK/Ri8tL6alVv38ZVpJWSkalI1EUlcCv2zOD6pWlFuL269bEjQ5YiInJeY\nQt/MppvZRjMLmdncU2y/18zWmdm7ZvaSmQ2L2nanmW2O/LmzPYuPh9+9Xcnm6kN8/aZR9EhRHyki\nie2sKWZmKcBjwM3AWOA2MxvbqtlqoNTdxwHPAQ9FntsP+DYwCZgIfNvM+rZf+R2r/lgTP1i8iYuH\nZDP9wgFBlyMict5iOXSdCITcvdzdjwJPAzOjG7j7UneviyyuAAoij28CFrv7XnffBywGprdP6R3v\nP5dtZeeBev7l5tGYaVI1EUl8sYT+YKAiarkysu507gYWtuW5ZjbbzFaZ2aqampoYSup4++uO8vjS\nENeNyuPyopygyxERaRftepLazG4HSoGH2/I8d5/n7qXuXpqXl9eeJZ2zf3+5jNqGRu7TpGoi0oXE\nEvpVQPSwlYLIuhOY2TTgm8AMd29oy3M7mx37j/Afy7bysQmDGTOwd9DliIi0m1hCfyVQYmbDzSwV\nmAXMj25gZhOAJwkHfnXUpkXAjWbWN3IB98bIuk7tB4s3gcO9N4wMuhQRkXZ11m8auXujmc0hHNYp\nwFPuvtbM7gdWuft8wqdzMoFnIxc8t7v7DHffa2bfIdxxANzv7ns75DdpJxs/qOV3b1fy2SuHU9BX\nk6qJSNcS09dL3X0BsKDVum9FPZ52huc+BTx1rgXG28OLNtArrTtf0qRqItIF6dtGUd7cspcX11dz\nz7Uj6NsrNehyRETanUI/wt35fwvXk987jc9M1qRqItI1KfQjFq3dxert+/nqtJH0TE0JuhwRkQ6h\n0Acam5p5aNEGRuT14uOXFpz9CSIiCUqhDzz7ViXlNYe5b/poumtSNRHpwpI+4Y4cDU+qdsnQbG4c\nmx90OSIiHSrpQ/+p17dQXdvAv3xojCZVE5EuL6lDf9/hozzxchnTxuRzWWG/oMsREelwSR36jy4N\ncfhoI/dNHxV0KSIicZG0oV+xt45fLt/Gxy8tYGR+VtDliIjERdKG/g8Wb8IMvjJNk6qJSPJIytBf\nt+Mgf1hTxV1XFjIou2fQ5YiIxE1Shv5DizaQldadL16jSdVEJLkkXegvK9vNyxtr+NJ1xfTJ6BF0\nOSIicZVUoe/uPLhwAwP7pHPn5MKgyxERibukCv2F73/AO5UH+OoNI0nvoUnVRCT5JE3oH2tq5uFF\nGxmZn8ktl2hSNRFJTkkT+k+vrGDL7sN8Y/poUrppugURSU5JEfqHGxr50YubmVjYj6mj+wddjohI\nYGIKfTObbmYbzSxkZnNPsf1qM3vbzBrN7OOttj1oZu9H/tzaXoW3xc/+uoXdhxr4xs2jNamaiCS1\ns4a+maUAjwE3A2OB28xsbKtm24G7gN+0eu6HgUuA8cAk4Gtm1vv8y47dnkMNPPlKGTddkM+lw/rG\n86VFRDqdWI70JwIhdy9396PA08DM6AbuvtXd3wWaWz13LPCquze6+2HgXWB6O9Qds0eWhDhyrImv\n3zQ6ni8rItIpxRL6g4GKqOXKyLpYvANMN7MMM8sFrgOGtK3Ec7d9Tx2/fmMbt142hOL+mfF6WRGR\nTqt7R/5wd3/BzC4DlgE1wHKgqXU7M5sNzAYYOnRou73+9xZvJKWbaVI1EZGIWI70qzjx6Lwgsi4m\n7v5/3H28u98AGLDpFG3muXupu5fm5eXF+qPP6P2qA/xpzQ7uvmo4+b3T2+VniogkulhCfyVQYmbD\nzSwVmAXMj+WHm1mKmeVEHo8DxgEvnGuxbfHg8xvIzujBP1wzIh4vJyKSEM4a+u7eCMwBFgHrgWfc\nfa2Z3W9mMwDM7DIzqwQ+ATxpZmsjT+8BvGZm64B5wO2Rn9ehXttcw2ubdzPnumJ6p2tSNRGR42I6\np+/uC4AFrdZ9K+rxSsKnfVo/r57wCJ64aW52Hnx+A4Oze3LHFcPi+dIiIp1el/tG7l/e28n7VQf5\n5xtHktZdk6qJiETrUqF/tLGZ7y7ayOgBWcwcH+uoUhGR5NGlQv+3b25n+946vnGzJlUTETmVLhP6\nhxoa+fFLm7m8qB/XjmyfYZ8iIl1Nh345K57qGhopLezLPdcWa1I1EZHT6DKh3793Ok/eURp0GSIi\nnVqXOb07xB90AAAEfUlEQVQjIiJnp9AXEUkiCn0RkSSi0BcRSSIKfRGRJKLQFxFJIgp9EZEkotAX\nEUki5u5B13ACM6sBtp3Hj8gFdrdTOe1JdbWN6mob1dU2XbGuYe5+1jloOl3ony8zW+Xune6ruaqr\nbVRX26iutknmunR6R0QkiSj0RUSSSFcM/XlBF3AaqqttVFfbqK62Sdq6utw5fREROb2ueKQvIiKn\nkZChb2bTzWyjmYXMbO4ptqeZ2X9Ftr9hZoWdpK67zKzGzNZE/nwuTnU9ZWbVZvb+ababmf04Uve7\nZnZJJ6nrWjM7ELW/vhWnuoaY2VIzW2dma83sn07RJu77LMa64r7PzCzdzN40s3cidf2vU7SJ+3sy\nxroCeU9GXjvFzFab2V9Osa3j9pe7J9QfIAUoA4qAVOAdYGyrNl8Enog8ngX8Vyep6y7g0QD22dXA\nJcD7p9n+IWAhYMDlwBudpK5rgb8EsL8GApdEHmcBm07xbxn3fRZjXXHfZ5F9kBl53AN4A7i8VZsg\n3pOx1BXIezLy2vcCvznVv1dH7q9EPNKfCITcvdzdjwJPAzNbtZkJ/Dzy+Dngeuv4eyjGUlcg3P1V\nYO8ZmswEfuFhK4BsMxvYCeoKhLvvdPe3I49rgfXA4FbN4r7PYqwr7iL74FBksUfkT+uLhXF/T8ZY\nVyDMrAD4MPDT0zTpsP2ViKE/GKiIWq7k5P/4LW3cvRE4AOR0groAbomcDnjOzIZ0cE2xirX2IFwR\n+Xi+0MwuiPeLRz5WTyB8lBgt0H12hroggH0WOVWxBqgGFrv7afdXHN+TsdQFwbwnfwjcBzSfZnuH\n7a9EDP1E9meg0N3HAYv5W08up/Y24a+WXww8Avwxni9uZpnA74CvuPvBeL72mZylrkD2mbs3uft4\noACYaGYXxuN1zyaGuuL+njSzjwDV7v5WR7/WqSRi6FcB0b1xQWTdKduYWXegD7An6LrcfY+7N0QW\nfwpc2sE1xSqWfRp37n7w+Mdzd18A9DCz3Hi8tpn1IBysv3b335+iSSD77Gx1BbnPIq+5H1gKTG+1\nKYj35FnrCug9eSUww8y2Ej4NPNXMftWqTYftr0QM/ZVAiZkNN7NUwhc55rdqMx+4M/L448ASj1wR\nCbKuVud8ZxA+J9sZzAc+HRmRcjlwwN13Bl2UmQ04fh7TzCYS/v/a4UERec2fAevd/funaRb3fRZL\nXUHsMzPLM7PsyOOewA3AhlbN4v6ejKWuIN6T7v4v7l7g7oWEc2KJu9/eqlmH7a/u7fFD4sndG81s\nDrCI8IiZp9x9rZndD6xy9/mE3xi/NLMQ4QuFszpJXf9oZjOAxkhdd3V0XQBm9lvCozpyzawS+Dbh\ni1q4+xPAAsKjUUJAHfCZTlLXx4F7zKwROALMikPnDeEjsTuA9yLngwH+FRgaVVsQ+yyWuoLYZwOB\nn5tZCuFO5hl3/0vQ78kY6wrkPXkq8dpf+kauiEgSScTTOyIico4U+iIiSUShLyKSRBT6IiJJRKEv\nIpJEFPoiIklEoS8ikkQU+iIiSeT/AyKC04CrqJrkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x218344128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(sentence_accs)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
